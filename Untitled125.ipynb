{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "17332a2205084d29bebdd531724016de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a23452db8a9468395299a80efed5b67",
              "IPY_MODEL_2779b519e1e444cc9f689ce7575002a2",
              "IPY_MODEL_0d8064e97e444896b7b8637b5641ff38"
            ],
            "layout": "IPY_MODEL_7aaa1a0eeecd4d1d88444044595d6982"
          }
        },
        "0a23452db8a9468395299a80efed5b67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa9047fd43714e2aa27aa5eb891c5a74",
            "placeholder": "​",
            "style": "IPY_MODEL_308fcd7847fd49daa7204b1daa166f3d",
            "value": "modules.json: 100%"
          }
        },
        "2779b519e1e444cc9f689ce7575002a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94b977511b90434b8d5c0f3d47ec2b66",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_961cc30a48b94ad18687e50ce32d84b4",
            "value": 349
          }
        },
        "0d8064e97e444896b7b8637b5641ff38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5276986b857e4daeaebcc1618b01a451",
            "placeholder": "​",
            "style": "IPY_MODEL_9c23bcc9cf374309910167ad71dca18d",
            "value": " 349/349 [00:00&lt;00:00, 36.8kB/s]"
          }
        },
        "7aaa1a0eeecd4d1d88444044595d6982": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa9047fd43714e2aa27aa5eb891c5a74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "308fcd7847fd49daa7204b1daa166f3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94b977511b90434b8d5c0f3d47ec2b66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "961cc30a48b94ad18687e50ce32d84b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5276986b857e4daeaebcc1618b01a451": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c23bcc9cf374309910167ad71dca18d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0e31204210c4defb9d9baaac1d8943c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b213e0e1d5ee4d4a9d2cf9217283f0b2",
              "IPY_MODEL_63bab19522124ce5ac1cd80eaa1a3869",
              "IPY_MODEL_4b0ae6f08bbd462a865f7464daa50c11"
            ],
            "layout": "IPY_MODEL_bcf935770d5843089c2f3fd3e38b480a"
          }
        },
        "b213e0e1d5ee4d4a9d2cf9217283f0b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88552a06e024459c9f421dda5e3695cc",
            "placeholder": "​",
            "style": "IPY_MODEL_9359e031c82840ae90f43a898c98fdaa",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "63bab19522124ce5ac1cd80eaa1a3869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfb73cc6b6ca47888cc30711a859c7d8",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9bb1c928985405790edd31a59de74a3",
            "value": 116
          }
        },
        "4b0ae6f08bbd462a865f7464daa50c11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fc9aa99b3fa4bb1bd37eb16060d5cc8",
            "placeholder": "​",
            "style": "IPY_MODEL_dc84f34f42404a518550975c65bb8936",
            "value": " 116/116 [00:00&lt;00:00, 12.2kB/s]"
          }
        },
        "bcf935770d5843089c2f3fd3e38b480a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88552a06e024459c9f421dda5e3695cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9359e031c82840ae90f43a898c98fdaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfb73cc6b6ca47888cc30711a859c7d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9bb1c928985405790edd31a59de74a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2fc9aa99b3fa4bb1bd37eb16060d5cc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc84f34f42404a518550975c65bb8936": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80bd1fa3411f43139cdc580fe820ee4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_61d7a2397e7543c189372ddd80f21f18",
              "IPY_MODEL_028897de39ae4b92892801b5a1124467",
              "IPY_MODEL_734a680f84f54c39ba1f9bb7f4246fcc"
            ],
            "layout": "IPY_MODEL_810f649efb9b4f8daad714e9ebe52183"
          }
        },
        "61d7a2397e7543c189372ddd80f21f18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d45e72330174d9192ceab5e23bee52a",
            "placeholder": "​",
            "style": "IPY_MODEL_1852fd3121a64dc08af88eacb699aa38",
            "value": "README.md: 100%"
          }
        },
        "028897de39ae4b92892801b5a1124467": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ed6115db9224644961e763a6977d1a7",
            "max": 10454,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_659809be3e864d3384769c740b95ba0d",
            "value": 10454
          }
        },
        "734a680f84f54c39ba1f9bb7f4246fcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_461862df7fa84c69aa7669d059f1bf92",
            "placeholder": "​",
            "style": "IPY_MODEL_95b24cd7a25047e5a63d1231db83e728",
            "value": " 10.5k/10.5k [00:00&lt;00:00, 1.07MB/s]"
          }
        },
        "810f649efb9b4f8daad714e9ebe52183": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d45e72330174d9192ceab5e23bee52a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1852fd3121a64dc08af88eacb699aa38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ed6115db9224644961e763a6977d1a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "659809be3e864d3384769c740b95ba0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "461862df7fa84c69aa7669d059f1bf92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95b24cd7a25047e5a63d1231db83e728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc68bf25e4b249acab58e6b4926ecb61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c8d5d5ae1bd43bdaff46db02897bd2c",
              "IPY_MODEL_803a9d23d1e0433d9c19f9891dfa5e2b",
              "IPY_MODEL_fc11bdac5476474099f17e2ee3efc00c"
            ],
            "layout": "IPY_MODEL_e5ae786e665d438da9625f31571eefbd"
          }
        },
        "4c8d5d5ae1bd43bdaff46db02897bd2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e27427994a9f44e98d1929a59d39c502",
            "placeholder": "​",
            "style": "IPY_MODEL_21af89cd42e94a4a93986a0dbee6e95c",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "803a9d23d1e0433d9c19f9891dfa5e2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_048731d68827469c9b935a3f5860347f",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea3b9cc65e294abf97522b04bafbbcfe",
            "value": 53
          }
        },
        "fc11bdac5476474099f17e2ee3efc00c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4336cccbb8de460e9db764ada8648f7a",
            "placeholder": "​",
            "style": "IPY_MODEL_bd961322d252439a9e9c643950fa62b0",
            "value": " 53.0/53.0 [00:00&lt;00:00, 5.58kB/s]"
          }
        },
        "e5ae786e665d438da9625f31571eefbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e27427994a9f44e98d1929a59d39c502": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21af89cd42e94a4a93986a0dbee6e95c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "048731d68827469c9b935a3f5860347f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea3b9cc65e294abf97522b04bafbbcfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4336cccbb8de460e9db764ada8648f7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd961322d252439a9e9c643950fa62b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32dfdc93f7ac43bc8e62d171b4571716": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_94760365ab674d7782030999b69c9a0f",
              "IPY_MODEL_f30653ee0a1549b4bba35758f0fbd4b0",
              "IPY_MODEL_d8d5056e14f74151b42cdad0edd7c8f8"
            ],
            "layout": "IPY_MODEL_ac77b3ff3fa64056ae60714dbbe5f015"
          }
        },
        "94760365ab674d7782030999b69c9a0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_529c7e24263c49b38cc4e6605036453a",
            "placeholder": "​",
            "style": "IPY_MODEL_bac93ca3e5d34e72a109f5e996002c67",
            "value": "config.json: 100%"
          }
        },
        "f30653ee0a1549b4bba35758f0fbd4b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af7158c5f0514071b9b207792fb1272f",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d9a82dd13d9144af8cc74b61221f2ce9",
            "value": 612
          }
        },
        "d8d5056e14f74151b42cdad0edd7c8f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d3627cdbf544852a2cd63f9b029ccfc",
            "placeholder": "​",
            "style": "IPY_MODEL_cb08c959e0054cdd85cc6302b3fa7946",
            "value": " 612/612 [00:00&lt;00:00, 48.9kB/s]"
          }
        },
        "ac77b3ff3fa64056ae60714dbbe5f015": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "529c7e24263c49b38cc4e6605036453a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bac93ca3e5d34e72a109f5e996002c67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af7158c5f0514071b9b207792fb1272f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9a82dd13d9144af8cc74b61221f2ce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d3627cdbf544852a2cd63f9b029ccfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb08c959e0054cdd85cc6302b3fa7946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0ef690d72254a51a126d75dc4046dc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0d9bcfd638346bfae93d36bd215529e",
              "IPY_MODEL_254a052f49544ad99aa6e2d112e84578",
              "IPY_MODEL_8bbde4202fdc4dcdacf53576f40f773f"
            ],
            "layout": "IPY_MODEL_0c9726b584da4b0da0e9552340e7af7b"
          }
        },
        "e0d9bcfd638346bfae93d36bd215529e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a397583f1424e1aa7565715605f3f8b",
            "placeholder": "​",
            "style": "IPY_MODEL_91268858190c437db5cb69a503fb8847",
            "value": "model.safetensors: 100%"
          }
        },
        "254a052f49544ad99aa6e2d112e84578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_225f764bc6184dc78c738f26b8fa5a79",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87613009c364450e91a06f384aca239d",
            "value": 90868376
          }
        },
        "8bbde4202fdc4dcdacf53576f40f773f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce85c9159ee247a189d4b2ce6792a5a1",
            "placeholder": "​",
            "style": "IPY_MODEL_f284bc221a304dadadba28d45767a780",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 169MB/s]"
          }
        },
        "0c9726b584da4b0da0e9552340e7af7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a397583f1424e1aa7565715605f3f8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91268858190c437db5cb69a503fb8847": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "225f764bc6184dc78c738f26b8fa5a79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87613009c364450e91a06f384aca239d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce85c9159ee247a189d4b2ce6792a5a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f284bc221a304dadadba28d45767a780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eba54c0302f14155b8aefbc090e6a296": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4af680753d64799ab462914d6d273e7",
              "IPY_MODEL_356e965f26404008ac9b893b7251531d",
              "IPY_MODEL_6e1660b749c74105b83cf9b7da3e1e58"
            ],
            "layout": "IPY_MODEL_9afb132c95c84a30b311b1b3bec6ecdb"
          }
        },
        "c4af680753d64799ab462914d6d273e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0b25232813a4bd6967ee50eb5f7cf5e",
            "placeholder": "​",
            "style": "IPY_MODEL_596762c6b08e4a33801bb4ed8ff36781",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "356e965f26404008ac9b893b7251531d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e9c56d980d54322bd88e85a899f7364",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2e076f519b09480f9b73a3c27a61ad4e",
            "value": 350
          }
        },
        "6e1660b749c74105b83cf9b7da3e1e58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4d9e3a4e02b43d08e54f1810985de12",
            "placeholder": "​",
            "style": "IPY_MODEL_6cc4f91ffad44cba8e4d6a45632cf74c",
            "value": " 350/350 [00:00&lt;00:00, 40.4kB/s]"
          }
        },
        "9afb132c95c84a30b311b1b3bec6ecdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0b25232813a4bd6967ee50eb5f7cf5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "596762c6b08e4a33801bb4ed8ff36781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e9c56d980d54322bd88e85a899f7364": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e076f519b09480f9b73a3c27a61ad4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e4d9e3a4e02b43d08e54f1810985de12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cc4f91ffad44cba8e4d6a45632cf74c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f3ea98fd36d472e9e0660f7b6635789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_848c3d4853a8481e93985d1c9e3c049a",
              "IPY_MODEL_60d6cc02df83497c88a2219121d359b2",
              "IPY_MODEL_d98443ab6fb64bb2a1abecd9e31e386d"
            ],
            "layout": "IPY_MODEL_4f0e8e91ea0845d588fcd35fc95712fe"
          }
        },
        "848c3d4853a8481e93985d1c9e3c049a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32c293dc26c94cc0ae6173c3452bd94c",
            "placeholder": "​",
            "style": "IPY_MODEL_04569c3048334fb9b33379722aa65efe",
            "value": "vocab.txt: 100%"
          }
        },
        "60d6cc02df83497c88a2219121d359b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f438d52951b473fb7683dc3259ef688",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93133f7765bd4bf8a8794e8616b73453",
            "value": 231508
          }
        },
        "d98443ab6fb64bb2a1abecd9e31e386d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9de44973279747eabf2e7e2c13c36271",
            "placeholder": "​",
            "style": "IPY_MODEL_2dcc3f48f4a34862b1c773dbad851ab4",
            "value": " 232k/232k [00:00&lt;00:00, 12.0MB/s]"
          }
        },
        "4f0e8e91ea0845d588fcd35fc95712fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32c293dc26c94cc0ae6173c3452bd94c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04569c3048334fb9b33379722aa65efe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f438d52951b473fb7683dc3259ef688": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93133f7765bd4bf8a8794e8616b73453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9de44973279747eabf2e7e2c13c36271": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dcc3f48f4a34862b1c773dbad851ab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e8b8689be9f43088c23383d8492c139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_193e99174f0040e3960aa62fb794adbe",
              "IPY_MODEL_0b10c09a4db94504920a38775b9645f6",
              "IPY_MODEL_a8fa471216f5451f81478750166c11fa"
            ],
            "layout": "IPY_MODEL_5d5d0f94fed04b56a73f363a82003120"
          }
        },
        "193e99174f0040e3960aa62fb794adbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1844da15856547319e79f921ba9480f1",
            "placeholder": "​",
            "style": "IPY_MODEL_ccb8583de7c142cb8a44cea2cfa806c0",
            "value": "tokenizer.json: 100%"
          }
        },
        "0b10c09a4db94504920a38775b9645f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f52fe005cbaa46d1a92f4a75d3541af0",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea4c5feefd7c439ea09e1fe25d873707",
            "value": 466247
          }
        },
        "a8fa471216f5451f81478750166c11fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_580de23c91924f48be0f840f6ca7232c",
            "placeholder": "​",
            "style": "IPY_MODEL_2a582ba0447a4038830665992bdab735",
            "value": " 466k/466k [00:00&lt;00:00, 7.18MB/s]"
          }
        },
        "5d5d0f94fed04b56a73f363a82003120": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1844da15856547319e79f921ba9480f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccb8583de7c142cb8a44cea2cfa806c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f52fe005cbaa46d1a92f4a75d3541af0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea4c5feefd7c439ea09e1fe25d873707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "580de23c91924f48be0f840f6ca7232c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a582ba0447a4038830665992bdab735": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fafbd507a6a42b29fa7dbc98c9306e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b22909522404ab983fa66d0b2b14238",
              "IPY_MODEL_47943d52958e4a7f9d2fa57b4641d957",
              "IPY_MODEL_52692e202df044c9b793f7aac29b898d"
            ],
            "layout": "IPY_MODEL_8e35fd328e80410483168922c70fef9f"
          }
        },
        "3b22909522404ab983fa66d0b2b14238": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09d1ff8b782e47fcbda60166e2443a65",
            "placeholder": "​",
            "style": "IPY_MODEL_d737a2dd3dd847a6aae182909ced47dc",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "47943d52958e4a7f9d2fa57b4641d957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6efa32e5f974f429388bfc1ecb3a8ec",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fbabcb34a8fe4c788652d5cc0dd6f498",
            "value": 112
          }
        },
        "52692e202df044c9b793f7aac29b898d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a7428ae7ae640dfa74966f09a1e79a8",
            "placeholder": "​",
            "style": "IPY_MODEL_942ad5db6021446688676a33493a0719",
            "value": " 112/112 [00:00&lt;00:00, 7.22kB/s]"
          }
        },
        "8e35fd328e80410483168922c70fef9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09d1ff8b782e47fcbda60166e2443a65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d737a2dd3dd847a6aae182909ced47dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6efa32e5f974f429388bfc1ecb3a8ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbabcb34a8fe4c788652d5cc0dd6f498": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a7428ae7ae640dfa74966f09a1e79a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "942ad5db6021446688676a33493a0719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0add55a4fcae40a49386d0b476df1968": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27a400c960394e428444ce9027448d4d",
              "IPY_MODEL_2c82ef4e04804bd39db53e4008e9f293",
              "IPY_MODEL_6e61a510c3fa438f9d3c0794daaed809"
            ],
            "layout": "IPY_MODEL_f9ca65c82115476ba7e00a994477b8da"
          }
        },
        "27a400c960394e428444ce9027448d4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f29d3fd8ccf446999367a45eb22dfc3",
            "placeholder": "​",
            "style": "IPY_MODEL_2da765b0851543c6a42b628bccaaaa4d",
            "value": "config.json: 100%"
          }
        },
        "2c82ef4e04804bd39db53e4008e9f293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c35307d63470411e8954f74371eecf08",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a2d9fd756f7f4125a43ad79e0f82abfd",
            "value": 190
          }
        },
        "6e61a510c3fa438f9d3c0794daaed809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4a77a2cdfba437fb20690307598ae9d",
            "placeholder": "​",
            "style": "IPY_MODEL_44f11fd71d6e42a387b7dec0b3750f21",
            "value": " 190/190 [00:00&lt;00:00, 20.7kB/s]"
          }
        },
        "f9ca65c82115476ba7e00a994477b8da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f29d3fd8ccf446999367a45eb22dfc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2da765b0851543c6a42b628bccaaaa4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c35307d63470411e8954f74371eecf08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2d9fd756f7f4125a43ad79e0f82abfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b4a77a2cdfba437fb20690307598ae9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44f11fd71d6e42a387b7dec0b3750f21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6OCVHQznwgr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q6WtLdAXun1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2 langchain faiss-cpu"
      ],
      "metadata": {
        "id": "AXYaZwfrun6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiG8khFqvHEC",
        "outputId": "0591e155-4226-42a2-ec45-0265429490d4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.51 (from langchain-community)\n",
            "  Downloading langchain_core-0.3.51-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain<1.0.0,>=0.3.23 (from langchain-community)\n",
            "  Downloading langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.23)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain<1.0.0,>=0.3.23->langchain-community)\n",
            "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain-community) (2.11.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (4.13.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (0.4.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain-0.3.23-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.51-py3-none-any.whl (423 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.3/423.3 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.50\n",
            "    Uninstalling langchain-core-0.3.50:\n",
            "      Successfully uninstalled langchain-core-0.3.50\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.7\n",
            "    Uninstalling langchain-text-splitters-0.3.7:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.7\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.22\n",
            "    Uninstalling langchain-0.3.22:\n",
            "      Successfully uninstalled langchain-0.3.22\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.23 langchain-community-0.3.21 langchain-core-0.3.51 langchain-text-splitters-0.3.8 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from google.colab import drive\n",
        "\n",
        "# تثبيت الاعتمادات اللازمة\n",
        "!pip install PyPDF2 langchain faiss-cpu transformers torch\n",
        "\n",
        "# تهيئة النماذج\n",
        "def initialize_models():\n",
        "    # تحميل نموذج التضمين من Hugging Face\n",
        "    print(\"جاري تحميل نموذج التضمين...\")\n",
        "    embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "    # تحميل نموذج اللغة من Hugging Face\n",
        "    print(\"جاري تحميل نموذج اللغة Phi-3.5-mini-instruct-exl2...\")\n",
        "    model_id = \"bartowski/Phi-3.5-mini-instruct-exl2\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_id,\n",
        "        torch_dtype=torch.float16,\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "\n",
        "    return embedding_model, model, tokenizer\n",
        "\n",
        "# استخراج النص من ملف PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    print(f\"جاري استخراج النص من الملف: {pdf_path}\")\n",
        "    text = \"\"\n",
        "    try:\n",
        "        pdf_reader = PdfReader(pdf_path)\n",
        "        for page in pdf_reader.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "        print(f\"تم استخراج {len(text)} حرف من النص.\")\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"حدث خطأ أثناء قراءة ملف PDF: {e}\")\n",
        "        return None\n",
        "\n",
        "# تقسيم النص إلى أجزاء صغيرة\n",
        "def split_text(text):\n",
        "    print(\"جاري تقسيم النص إلى أجزاء...\")\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=200,\n",
        "        length_function=len\n",
        "    )\n",
        "    chunks = text_splitter.split_text(text)\n",
        "    print(f\"تم تقسيم النص إلى {len(chunks)} جزء.\")\n",
        "    return chunks\n",
        "\n",
        "# إنشاء قاعدة المعرفة (قاعدة البيانات المضمنة)\n",
        "def create_knowledge_base(chunks, embedding_model):\n",
        "    print(\"جاري إنشاء قاعدة المعرفة...\")\n",
        "    knowledge_base = FAISS.from_texts(chunks, embedding_model)\n",
        "    print(\"تم إنشاء قاعدة المعرفة بنجاح.\")\n",
        "    return knowledge_base\n",
        "\n",
        "# البحث عن المعلومات ذات الصلة\n",
        "def search_knowledge_base(knowledge_base, query, k=4):\n",
        "    print(f\"جاري البحث عن: {query}\")\n",
        "    docs = knowledge_base.similarity_search(query, k=k)\n",
        "    context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "    return context\n",
        "\n",
        "# توليد الإجابة باستخدام نموذج اللغة\n",
        "def generate_answer(model, tokenizer, context, query):\n",
        "    print(\"جاري توليد الإجابة...\")\n",
        "\n",
        "    prompt = f\"\"\"السياق:\n",
        "{context}\n",
        "\n",
        "السؤال:\n",
        "{query}\n",
        "\n",
        "الإجابة:\n",
        "\"\"\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=64,  # سياق بحجم 512\n",
        "        num_return_sequences=1,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        max_length=inputs.input_ids.shape[1] + 22  # توكن المخرجات 22\n",
        "    )\n",
        "\n",
        "    answer = tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)\n",
        "    return answer\n",
        "\n",
        "# الدالة الرئيسية\n",
        "def main():\n",
        "    print(\"برنامج RAG مع كتاب PDF\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # الاتصال بجوجل درايف (اختياري)\n",
        "    try:\n",
        "        drive.mount('/content/drive')\n",
        "        print(\"تم الاتصال بجوجل درايف بنجاح.\")\n",
        "    except:\n",
        "        print(\"لم يتم الاتصال بجوجل درايف، سيتم استخدام المسارات المحلية.\")\n",
        "\n",
        "    # تهيئة النماذج\n",
        "    embedding_model, llm_model, tokenizer = initialize_models()\n",
        "\n",
        "    # طلب مسار الكتاب PDF من المستخدم\n",
        "    pdf_path = input(\"أدخل مسار ملف PDF (على سبيل المثال: /content/drive/MyDrive/book.pdf): \")\n",
        "\n",
        "    # استخراج النص وإنشاء قاعدة المعرفة\n",
        "    text = extract_text_from_pdf(pdf_path)\n",
        "    if text:\n",
        "        chunks = split_text(text)\n",
        "        knowledge_base = create_knowledge_base(chunks, embedding_model)\n",
        "\n",
        "        # حلقة استعلام المستخدم\n",
        "        while True:\n",
        "            query = input(\"\\nأدخل سؤالك (أو اكتب 'خروج' للخروج): \")\n",
        "            if query.lower() == 'خروج' or query.lower() == 'exit':\n",
        "                break\n",
        "\n",
        "            # استرجاع السياق ذي الصلة\n",
        "            context = search_knowledge_base(knowledge_base, query)\n",
        "\n",
        "            # توليد الإجابة\n",
        "            answer = generate_answer(llm_model, tokenizer, context, query)\n",
        "\n",
        "            print(\"\\nالإجابة:\")\n",
        "            print(\"-\" * 50)\n",
        "            print(answer)\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "    print(\"تم إنهاء البرنامج.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "17332a2205084d29bebdd531724016de",
            "0a23452db8a9468395299a80efed5b67",
            "2779b519e1e444cc9f689ce7575002a2",
            "0d8064e97e444896b7b8637b5641ff38",
            "7aaa1a0eeecd4d1d88444044595d6982",
            "fa9047fd43714e2aa27aa5eb891c5a74",
            "308fcd7847fd49daa7204b1daa166f3d",
            "94b977511b90434b8d5c0f3d47ec2b66",
            "961cc30a48b94ad18687e50ce32d84b4",
            "5276986b857e4daeaebcc1618b01a451",
            "9c23bcc9cf374309910167ad71dca18d",
            "b0e31204210c4defb9d9baaac1d8943c",
            "b213e0e1d5ee4d4a9d2cf9217283f0b2",
            "63bab19522124ce5ac1cd80eaa1a3869",
            "4b0ae6f08bbd462a865f7464daa50c11",
            "bcf935770d5843089c2f3fd3e38b480a",
            "88552a06e024459c9f421dda5e3695cc",
            "9359e031c82840ae90f43a898c98fdaa",
            "dfb73cc6b6ca47888cc30711a859c7d8",
            "a9bb1c928985405790edd31a59de74a3",
            "2fc9aa99b3fa4bb1bd37eb16060d5cc8",
            "dc84f34f42404a518550975c65bb8936",
            "80bd1fa3411f43139cdc580fe820ee4c",
            "61d7a2397e7543c189372ddd80f21f18",
            "028897de39ae4b92892801b5a1124467",
            "734a680f84f54c39ba1f9bb7f4246fcc",
            "810f649efb9b4f8daad714e9ebe52183",
            "1d45e72330174d9192ceab5e23bee52a",
            "1852fd3121a64dc08af88eacb699aa38",
            "0ed6115db9224644961e763a6977d1a7",
            "659809be3e864d3384769c740b95ba0d",
            "461862df7fa84c69aa7669d059f1bf92",
            "95b24cd7a25047e5a63d1231db83e728",
            "cc68bf25e4b249acab58e6b4926ecb61",
            "4c8d5d5ae1bd43bdaff46db02897bd2c",
            "803a9d23d1e0433d9c19f9891dfa5e2b",
            "fc11bdac5476474099f17e2ee3efc00c",
            "e5ae786e665d438da9625f31571eefbd",
            "e27427994a9f44e98d1929a59d39c502",
            "21af89cd42e94a4a93986a0dbee6e95c",
            "048731d68827469c9b935a3f5860347f",
            "ea3b9cc65e294abf97522b04bafbbcfe",
            "4336cccbb8de460e9db764ada8648f7a",
            "bd961322d252439a9e9c643950fa62b0",
            "32dfdc93f7ac43bc8e62d171b4571716",
            "94760365ab674d7782030999b69c9a0f",
            "f30653ee0a1549b4bba35758f0fbd4b0",
            "d8d5056e14f74151b42cdad0edd7c8f8",
            "ac77b3ff3fa64056ae60714dbbe5f015",
            "529c7e24263c49b38cc4e6605036453a",
            "bac93ca3e5d34e72a109f5e996002c67",
            "af7158c5f0514071b9b207792fb1272f",
            "d9a82dd13d9144af8cc74b61221f2ce9",
            "0d3627cdbf544852a2cd63f9b029ccfc",
            "cb08c959e0054cdd85cc6302b3fa7946",
            "b0ef690d72254a51a126d75dc4046dc8",
            "e0d9bcfd638346bfae93d36bd215529e",
            "254a052f49544ad99aa6e2d112e84578",
            "8bbde4202fdc4dcdacf53576f40f773f",
            "0c9726b584da4b0da0e9552340e7af7b",
            "9a397583f1424e1aa7565715605f3f8b",
            "91268858190c437db5cb69a503fb8847",
            "225f764bc6184dc78c738f26b8fa5a79",
            "87613009c364450e91a06f384aca239d",
            "ce85c9159ee247a189d4b2ce6792a5a1",
            "f284bc221a304dadadba28d45767a780",
            "eba54c0302f14155b8aefbc090e6a296",
            "c4af680753d64799ab462914d6d273e7",
            "356e965f26404008ac9b893b7251531d",
            "6e1660b749c74105b83cf9b7da3e1e58",
            "9afb132c95c84a30b311b1b3bec6ecdb",
            "e0b25232813a4bd6967ee50eb5f7cf5e",
            "596762c6b08e4a33801bb4ed8ff36781",
            "6e9c56d980d54322bd88e85a899f7364",
            "2e076f519b09480f9b73a3c27a61ad4e",
            "e4d9e3a4e02b43d08e54f1810985de12",
            "6cc4f91ffad44cba8e4d6a45632cf74c",
            "5f3ea98fd36d472e9e0660f7b6635789",
            "848c3d4853a8481e93985d1c9e3c049a",
            "60d6cc02df83497c88a2219121d359b2",
            "d98443ab6fb64bb2a1abecd9e31e386d",
            "4f0e8e91ea0845d588fcd35fc95712fe",
            "32c293dc26c94cc0ae6173c3452bd94c",
            "04569c3048334fb9b33379722aa65efe",
            "0f438d52951b473fb7683dc3259ef688",
            "93133f7765bd4bf8a8794e8616b73453",
            "9de44973279747eabf2e7e2c13c36271",
            "2dcc3f48f4a34862b1c773dbad851ab4",
            "1e8b8689be9f43088c23383d8492c139",
            "193e99174f0040e3960aa62fb794adbe",
            "0b10c09a4db94504920a38775b9645f6",
            "a8fa471216f5451f81478750166c11fa",
            "5d5d0f94fed04b56a73f363a82003120",
            "1844da15856547319e79f921ba9480f1",
            "ccb8583de7c142cb8a44cea2cfa806c0",
            "f52fe005cbaa46d1a92f4a75d3541af0",
            "ea4c5feefd7c439ea09e1fe25d873707",
            "580de23c91924f48be0f840f6ca7232c",
            "2a582ba0447a4038830665992bdab735",
            "3fafbd507a6a42b29fa7dbc98c9306e2",
            "3b22909522404ab983fa66d0b2b14238",
            "47943d52958e4a7f9d2fa57b4641d957",
            "52692e202df044c9b793f7aac29b898d",
            "8e35fd328e80410483168922c70fef9f",
            "09d1ff8b782e47fcbda60166e2443a65",
            "d737a2dd3dd847a6aae182909ced47dc",
            "a6efa32e5f974f429388bfc1ecb3a8ec",
            "fbabcb34a8fe4c788652d5cc0dd6f498",
            "7a7428ae7ae640dfa74966f09a1e79a8",
            "942ad5db6021446688676a33493a0719",
            "0add55a4fcae40a49386d0b476df1968",
            "27a400c960394e428444ce9027448d4d",
            "2c82ef4e04804bd39db53e4008e9f293",
            "6e61a510c3fa438f9d3c0794daaed809",
            "f9ca65c82115476ba7e00a994477b8da",
            "4f29d3fd8ccf446999367a45eb22dfc3",
            "2da765b0851543c6a42b628bccaaaa4d",
            "c35307d63470411e8954f74371eecf08",
            "a2d9fd756f7f4125a43ad79e0f82abfd",
            "b4a77a2cdfba437fb20690307598ae9d",
            "44f11fd71d6e42a387b7dec0b3750f21"
          ]
        },
        "id": "PV2QWjepun85",
        "outputId": "836ce712-98ad-46d4-d0e9-6aa7cecf438f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.51)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.23)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "برنامج RAG مع كتاب PDF\n",
            "==================================================\n",
            "Mounted at /content/drive\n",
            "تم الاتصال بجوجل درايف بنجاح.\n",
            "جاري تحميل نموذج التضمين...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-c7c2fd247fe4>:17: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17332a2205084d29bebdd531724016de"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0e31204210c4defb9d9baaac1d8943c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80bd1fa3411f43139cdc580fe820ee4c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc68bf25e4b249acab58e6b4926ecb61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32dfdc93f7ac43bc8e62d171b4571716"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0ef690d72254a51a126d75dc4046dc8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eba54c0302f14155b8aefbc090e6a296"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f3ea98fd36d472e9e0660f7b6635789"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e8b8689be9f43088c23383d8492c139"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3fafbd507a6a42b29fa7dbc98c9306e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0add55a4fcae40a49386d0b476df1968"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "جاري تحميل نموذج اللغة Phi-3.5-mini-instruct-exl2...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Can't load tokenizer for 'bartowski/Phi-3.5-mini-instruct-exl2'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'bartowski/Phi-3.5-mini-instruct-exl2' is the correct path to a directory containing all relevant files for a BartTokenizerFast tokenizer.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-c7c2fd247fe4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-c7c2fd247fe4>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;31m# تهيئة النماذج\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0membedding_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;31m# طلب مسار الكتاب PDF من المستخدم\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-c7c2fd247fe4>\u001b[0m in \u001b[0;36minitialize_models\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"جاري تحميل نموذج اللغة Phi-3.5-mini-instruct-exl2...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mmodel_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"bartowski/Phi-3.5-mini-instruct-exl2\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     model = AutoModelForCausalLM.from_pretrained(\n\u001b[1;32m     24\u001b[0m         \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtokenizer_class_fast\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muse_fast\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtokenizer_class_py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer_class_fast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    993\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtokenizer_class_py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2044\u001b[0m         \u001b[0;31m# loaded directly from the GGUF file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_file_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfull_file_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresolved_vocab_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgguf_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2046\u001b[0;31m             raise EnvironmentError(\n\u001b[0m\u001b[1;32m   2047\u001b[0m                 \u001b[0;34mf\"Can't load tokenizer for '{pretrained_model_name_or_path}'. If you were trying to load it from \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2048\u001b[0m                 \u001b[0;34m\"'https://huggingface.co/models', make sure you don't have a local directory with the same name. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for 'bartowski/Phi-3.5-mini-instruct-exl2'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'bartowski/Phi-3.5-mini-instruct-exl2' is the correct path to a directory containing all relevant files for a BartTokenizerFast tokenizer."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "import torch\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "# تثبيت الاعتمادات (إذا كنت تعمل في بيئة مثل Colab)\n",
        "# !pip install -q PyPDF2 langchain faiss-cpu\n",
        "\n",
        "# دالة لاستخراج النص من ملف PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    print(f\"جاري استخراج النص من الملف: {pdf_path}\")\n",
        "    text = \"\"\n",
        "    try:\n",
        "        pdf_reader = PdfReader(pdf_path)\n",
        "        for page in pdf_reader.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                text += page_text + \"\\n\"\n",
        "        print(f\"تم استخراج {len(text)} حرف من النص.\")\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"حدث خطأ أثناء قراءة ملف PDF: {e}\")\n",
        "        return None\n",
        "\n",
        "# دالة لتقسيم النص إلى أجزاء صغيرة\n",
        "def split_text(text):\n",
        "    print(\"جاري تقسيم النص إلى أجزاء...\")\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=200,\n",
        "        length_function=len\n",
        "    )\n",
        "    chunks = text_splitter.split_text(text)\n",
        "    print(f\"تم تقسيم النص إلى {len(chunks)} جزء.\")\n",
        "    return chunks\n",
        "\n",
        "# إنشاء قاعدة المعرفة باستخدام FAISS\n",
        "def create_knowledge_base(chunks, embedding_model):\n",
        "    print(\"جاري إنشاء قاعدة المعرفة...\")\n",
        "    knowledge_base = FAISS.from_texts(chunks, embedding_model)\n",
        "    print(\"تم إنشاء قاعدة المعرفة بنجاح.\")\n",
        "    return knowledge_base\n",
        "\n",
        "# دالة لاسترجاع السياق من قاعدة المعرفة بناءً على استعلام المستخدم\n",
        "def search_knowledge_base(knowledge_base, query, k=4):\n",
        "    print(f\"جاري البحث عن: {query}\")\n",
        "    docs = knowledge_base.similarity_search(query, k=k)\n",
        "    context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "    return context\n",
        "\n",
        "# دالة لاستدعاء نموذج Exllama عبر subprocess\n",
        "def generate_answer_exllama(model_path, prompt):\n",
        "    \"\"\"\n",
        "    نفترض وجود سكريبت exllama_inference.py يقبل المعلمات:\n",
        "    --model : مسار النموذج\n",
        "    --prompt : النص الكامل (السياق والسؤال)\n",
        "    ويمكنك تعديل الخيارات مثل max_new_tokens وtemperature حسب الحاجة.\n",
        "    \"\"\"\n",
        "    command = [\n",
        "        \"python\", \"exllama_inference.py\",\n",
        "        \"--model\", model_path,\n",
        "        \"--prompt\", prompt,\n",
        "        # يمكنك إضافة معلمات أخرى مثل:\n",
        "        # \"--max_new_tokens\", \"64\",\n",
        "        # \"--temperature\", \"0.7\"\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        # تشغيل الأمر واستلام النتيجة\n",
        "        result = subprocess.run(command, capture_output=True, text=True, check=True)\n",
        "        output = result.stdout.strip()\n",
        "        return output\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(\"حدث خطأ أثناء استدعاء Exllama:\", e)\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    print(\"برنامج RAG مع كتاب PDF باستخدام نموذج Exllama\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # خطوات إعداد قاعدة المعرفة:\n",
        "    pdf_path = input(\"أدخل مسار ملف PDF (مثال: /content/drive/MyDrive/book.pdf): \").strip()\n",
        "    text = extract_text_from_pdf(pdf_path)\n",
        "    if not text:\n",
        "        return\n",
        "\n",
        "    # استخدم نموذج التضمين المناسب (يمكنك استخدام أي نموذج مناسب مثل sentence-transformers)\n",
        "    print(\"جاري تحميل نموذج التضمين...\")\n",
        "    embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    chunks = split_text(text)\n",
        "    knowledge_base = create_knowledge_base(chunks, embedding_model)\n",
        "\n",
        "    # مسار النموذج الخاص بـ Exllama (عدل المسار حسب مكان النموذج المحول)\n",
        "    model_path = input(\"أدخل مسار نموذج Exllama (مثال: /path/to/exllama_model): \").strip()\n",
        "\n",
        "    # حلقة استعلام المستخدم\n",
        "    while True:\n",
        "        query = input(\"\\nأدخل سؤالك (أو اكتب 'خروج' للخروج): \").strip()\n",
        "        if query.lower() in ['خروج', 'exit']:\n",
        "            break\n",
        "\n",
        "        # استرجاع السياق ذي الصلة\n",
        "        context = search_knowledge_base(knowledge_base, query)\n",
        "\n",
        "        # إنشاء prompt يحتوي على السياق والسؤال\n",
        "        prompt = f\"\"\"السياق:\n",
        "{context}\n",
        "\n",
        "السؤال:\n",
        "{query}\n",
        "\n",
        "الإجابة:\"\"\"\n",
        "\n",
        "        # استدعاء نموذج Exllama لتوليد الإجابة\n",
        "        answer = generate_answer_exllama(model_path, prompt)\n",
        "\n",
        "        print(\"\\nالإجابة:\")\n",
        "        print(\"-\" * 50)\n",
        "        print(answer if answer else \"لم يتم توليد إجابة.\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    print(\"تم إنهاء البرنامج.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_zidLswxiHk",
        "outputId": "f7a6d376-157d-45bb-e65a-523883ef1fe0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "برنامج RAG مع كتاب PDF باستخدام نموذج Exllama\n",
            "==================================================\n",
            "أدخل مسار ملف PDF (مثال: /content/drive/MyDrive/book.pdf): /content/The_Little_Prince_Antoine_de_Saint_Exupery.pdf\n",
            "جاري استخراج النص من الملف: /content/The_Little_Prince_Antoine_de_Saint_Exupery.pdf\n",
            "تم استخراج 76733 حرف من النص.\n",
            "جاري تحميل نموذج التضمين...\n",
            "جاري تقسيم النص إلى أجزاء...\n",
            "تم تقسيم النص إلى 98 جزء.\n",
            "جاري إنشاء قاعدة المعرفة...\n",
            "تم إنشاء قاعدة المعرفة بنجاح.\n",
            "أدخل مسار نموذج Exllama (مثال: /path/to/exllama_model): /content/Phi-3.5-mini-instruct-exl2\n",
            "\n",
            "أدخل سؤالك (أو اكتب 'خروج' للخروج): What is the topic of the book?\n",
            "جاري البحث عن: What is the topic of the book?\n",
            "حدث خطأ أثناء استدعاء Exllama: Command '['python', 'exllama_inference.py', '--model', '/content/Phi-3.5-mini-instruct-exl2', '--prompt', 'السياق:\\ngrown-ups.\\tI\\tmust\\thave\\tgot\\tolder.\\nV\\nEvery\\tday\\tI\\tlearned\\tsomething\\ton\\tthe\\tplanet,\\ton\\tdeparture,\\ton\\tthe\\tjourney.\\tIt\\tcame\\tvery\\ngently,\\tat\\tthe\\tchance\\tof\\treflections.\\tThus,\\ton\\tthe\\tthird\\tday,\\tI\\tknew\\tthe\\tdrama\\tof\\tthe\\nbaobabs.\\nThis\\ttime\\tagain\\tit\\twas\\tthanks\\tto\\tthe\\tsheep,\\tfor\\tsuddenly\\tthe\\tlittle\\tprince\\tinterrogated\\tme,\\nas\\tif\\tcaught\\tin\\ta\\tserious\\tdoubt:\\n“It\\tis\\ttrue,\\tis\\tit\\tnot,\\tthat\\tsheep\\teat\\tthe\\tshrubs?”\\n-\\tYes.\\tThat\\tis\\ttrue.\\n“Ah!\\tI\\tam\\thappy\\t!\\t“\\nI\\tdid\\tnot\\tunderstand\\twhy\\tit\\twas\\tso\\timportant\\tthat\\tthe\\tsheep\\tate\\tthe\\tshrubs.\\tBut\\tthe\\tlittle\\nprince\\tadded:\\n“So\\tthey\\talso\\teat\\tthe\\tbaobabs?”\\t“\\nI\\tremarked\\tto\\tthe\\tlittle\\tprince\\tthat\\tthe\\tbaobab\\ttrees\\tare\\tnot\\tshrubs,\\tbut\\ttrees\\tas\\tlarge\\tas\\nchurches,\\tand\\tthat\\teven\\tif\\tthey\\tcarried\\twith\\tthem\\ta\\twhole\\therd\\tof\\telephants,\\tthis\\tflock\\nwould\\tnot\\tbe\\table\\tto\\tovercome\\ta\\tsingle\\tbaobab\\t.\\nThe\\tidea\\tof\\tthe\\therd\\tof\\telephants\\tmade\\tthe\\tlittle\\tprince\\tlaugh:\\n“We\\tshould\\tput\\tthem\\ton\\ttop\\tof\\teach\\tother\\t…”\\n\\nmemories\\tof\\tone\\tof\\tthem\\tseem\\tinteresting\\tto\\thim,\\tthe\\tgeographer\\tmakes\\tinvestigate\\tthe\\nmorality\\tof\\tthe\\texplorer.\\n-\\tWhy\\tthis\\t?\\n“Because\\tan\\texplorer\\twho\\tlies\\twould\\tcause\\tcatastrophes\\tin\\tthe\\tbooks\\tof\\tgeography.”\\tAnd\\nalso\\tan\\texplorer\\twho\\twould\\tdrink\\ttoo\\tmuch.\\n-\\tWhy\\tthis\\t?\\tSaid\\tthe\\tlittle\\tprince.\\n“Because\\tdrunks\\tsee\\tdouble.”\\tThen\\tthe\\tgeographer\\twould\\tnote\\ttwo\\tmountains,\\twhere\\nthere\\tis\\tonly\\tone.\\n“I\\tknow\\tsomebody,”\\tsaid\\tthe\\tlittle\\tprince,\\twho\\twould\\tbe\\ta\\tbad\\texplorer.\\n-\\tIt’s\\tpossible.\\tSo\\twhen\\tthe\\tmorality\\tof\\tthe\\texplorer\\tseems\\tgood,\\tan\\tinquiry\\tis\\tmade\\tinto\\nhis\\tdiscovery.\\n-\\tWe\\twill\\tsee\\t?\\n-\\tNo.\\tIt’s\\ttoo\\tcomplicated.\\tBut\\tthe\\texplorer\\tis\\trequired\\tto\\tprovide\\tevidence.\\tIf,\\tfor\\nexample,\\tthe\\tdiscovery\\tof\\ta\\tlarge\\tmountain\\tis\\trequired,\\tit\\tis\\trequired\\tto\\tbring\\tlarge\\tstones.\\n“\\nThe\\tgeographer\\twas\\tsuddenly\\tmoved.\\n“But\\tyou\\tcome\\tfrom\\ta\\tdistance!\\tYou’re\\tan\\texplorer!\\tYou’re\\tgoing\\tto\\tdescribe\\tyour\\tplanet!\\n“\\nAnd\\tthe\\tgeographer,\\thaving\\topened\\this\\tregister,\\tcut\\this\\tpencil.\\tWe\\tfirst\\tnote\\tin\\tpencil\\tthe\\n\\nreserve.\\tI\\tsaid,\\t“Children!\\tPay\\tattention\\tto\\tthe\\tbaobabs!\\tIt\\twas\\tto\\twarn\\tmy\\tfriends\\tof\\tthe\\ndanger\\tthat\\tthey\\thad\\tbeen\\tfor\\ta\\tlong\\ttime,\\tlike\\tmyself,\\twithout\\tknowing\\tit,\\tthat\\tI\\thad\\nworked\\tso\\tmuch\\ton\\tthis\\tdrawing.\\tThe\\tlesson\\tI\\tgave\\twas\\tworth\\tit.\\tYou\\tmay\\twonder:\\tWhy\\nare\\tthere\\tnot\\tother\\tdrawings\\tin\\tthis\\tbook\\tas\\tgrandiose\\tas\\tthe\\tdrawing\\tof\\tthe\\tbaobabs?\\tThe\\nanswer\\tis\\tvery\\tsimple:\\tI\\ttried\\tbut\\tI\\tcould\\tnot\\tsucceed.\\tWhen\\tI\\tdrew\\tthe\\tbaobabs\\tI\\twas\\nanimated\\tby\\tthe\\tfeeling\\tof\\turgency.\\nVI\\nAh!\\tLittle\\tprince,\\tI\\thave\\tunderstood,\\tlittle\\tby\\tlittle,\\tyour\\tlittle\\tmelancholy\\tlife.\\tYou\\thad\\nonly\\tfor\\ta\\tlong\\tdistraction\\tthe\\tsweetness\\tof\\tthe\\tsunsets.\\tI\\tlearned\\tthis\\tnew\\tdetail,\\ton\\tthe\\nfourth\\tday\\tin\\tthe\\tmorning,\\twhen\\tyou\\tsaid\\tto\\tme:\\n“I\\tlike\\tthe\\tsunsets.\\tLet’s\\tsee\\ta\\tsunset\\t…\\n-\\tBut\\tyou\\thave\\tto\\twait…\\n-\\tWait\\tfor\\twhat\\t?\\n-\\tWait\\tuntil\\tthe\\tsun\\tgoes\\tdown.\\t“\\nYou\\tlooked\\tvery\\tsurprised\\tat\\tfirst,\\tand\\tthen\\tyou\\tlaughed\\tat\\tyourself.\\tAnd\\tyou\\tsaid\\tto\\tme:\\n”\\tI\\talways\\tfeel\\tat\\thome\\t!\\t“\\n\\nThis\\twas\\this\\tfirst\\tmovement\\tof\\tregret.\\tBut\\the\\tresumed\\this\\tcourage:\\n“What\\tdo\\tyou\\tadvise\\tme\\tto\\tvisit?”\\tHe\\tasked.\\n“Planet\\tEarth,”\\treplied\\tthe\\tgeographer.\\tShe\\thas\\ta\\tgood\\treputation\\t…\\t“\\nAnd\\tthe\\tlittle\\tprince\\twent\\taway,\\tthinking\\tof\\this\\tflower.\\nXVI\\nThe\\tseventh\\tplanet\\twas\\ttherefore\\tthe\\tEarth.\\nThe\\tEarth\\tis\\tnot\\ta\\tplanet\\tof\\tany\\tkind!\\tThere\\tare\\ta\\thundred\\tand\\televen\\tkings\\t(not\\nforgetting,\\tof\\tcourse,\\tthe\\tNegro\\tkings),\\tseven\\tthousand\\tgeographers,\\tnine\\thundred\\nthousand\\tbusinessmen,\\tseven\\tand\\ta\\thalf\\tmillion\\tdrunkards,\\tthree\\thundred\\tand\\televen\\nmillion\\tvain,\\tAbout\\ttwo\\tbillion\\tlarge\\tpeople.\\nTo\\tgive\\tyou\\tan\\tidea\\tof\\tthe\\tdimensions\\tof\\tthe\\tEarth,\\tI\\twill\\ttell\\tyou\\tthat\\tbefore\\tthe\\tinvention\\nof\\telectricity\\tthere\\twas\\tto\\tbe\\tmaintained\\ton\\tall\\tsix\\tcontinents\\ta\\tgenuine\\tarmy\\tof\\tfour\\nhundred\\tand\\tsixty-two\\tthousand\\tfive\\thundred\\tand\\televen\\tlighters\\tOf\\tstreet\\tlamps.\\nSeen\\tfrom\\ta\\tlittle\\tdistance\\tit\\tmade\\ta\\tsplendid\\teffect.\\tThe\\tmovements\\tof\\tthis\\tarmy\\twere\\n\\nالسؤال:\\nWhat is the topic of the book?\\n\\nالإجابة:']' returned non-zero exit status 2.\n",
            "\n",
            "الإجابة:\n",
            "--------------------------------------------------\n",
            "لم يتم توليد إجابة.\n",
            "--------------------------------------------------\n",
            "\n",
            "أدخل سؤالك (أو اكتب 'خروج' للخروج): خروج\n",
            "تم إنهاء البرنامج.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --single-branch --branch 3_5 https://huggingface.co/bartowski/Phi-3.5-mini-instruct-exl2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfqN0BMTyBpK",
        "outputId": "2a55edbc-1e4a-4cba-85c7-2b09eeb72d33"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Phi-3.5-mini-instruct-exl2'...\n",
            "remote: Enumerating objects: 26, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 26 (delta 0), reused 0 (delta 0), pack-reused 3 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (26/26), 566.80 KiB | 3.31 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/Phi-3.5-mini-instruct-exl2"
      ],
      "metadata": {
        "id": "f9ESzFWLyLGD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    print(f\"جاري استخراج النص من الملف: {pdf_path}\")\n",
        "    text = \"\"\n",
        "    try:\n",
        "        pdf_reader = PdfReader(pdf_path)\n",
        "        for page in pdf_reader.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                # تنظيف بسيط للنص؛ يمكنك تعديل ذلك حسب الحاجة\n",
        "                page_text = page_text.replace(\"\\r\", \" \").replace(\"\\t\", \" \")\n",
        "                text += page_text + \"\\n\"\n",
        "        print(f\"تم استخراج {len(text)} حرف من النص.\")\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"حدث خطأ أثناء قراءة ملف PDF: {e}\")\n",
        "        return None\n",
        "\n",
        "def split_text(text):\n",
        "    print(\"جاري تقسيم النص إلى أجزاء...\")\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, length_function=len)\n",
        "    chunks = splitter.split_text(text)\n",
        "    print(f\"تم تقسيم النص إلى {len(chunks)} جزء.\")\n",
        "    return chunks\n",
        "\n",
        "def create_knowledge_base(chunks, embedding_model):\n",
        "    print(\"جاري إنشاء قاعدة المعرفة...\")\n",
        "    kb = FAISS.from_texts(chunks, embedding_model)\n",
        "    print(\"تم إنشاء قاعدة المعرفة بنجاح.\")\n",
        "    return kb\n",
        "\n",
        "def search_knowledge_base(kb, query, k=4):\n",
        "    print(f\"جاري البحث عن: {query}\")\n",
        "    docs = kb.similarity_search(query, k=k)\n",
        "    context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "    return context\n",
        "\n",
        "def generate_answer_exllama(model_path, prompt):\n",
        "    \"\"\"\n",
        "    يقوم هذا الدالة باستدعاء سكريبت exllama_inference.py مع تمرير البرومبت والنموذج.\n",
        "    يتم إضافة معلمات إضافية للتوليد (max_new_tokens, temperature, top_p).\n",
        "    \"\"\"\n",
        "    command = [\n",
        "        \"python\", \"exllama_inference.py\",\n",
        "        \"--model\", model_path,\n",
        "        \"--prompt\", prompt,\n",
        "        \"--max_new_tokens\", \"64\",\n",
        "        \"--temperature\", \"0.7\",\n",
        "        \"--top_p\", \"0.9\"\n",
        "    ]\n",
        "    print(\"Executing command:\", \" \".join(command))\n",
        "    try:\n",
        "        result = subprocess.run(command, capture_output=True, text=True, check=True)\n",
        "        output = result.stdout.strip()\n",
        "        return output\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(\"حدث خطأ أثناء استدعاء Exllama:\", e)\n",
        "        print(\"stderr:\", e.stderr)\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    print(\"برنامج RAG مع كتاب PDF باستخدام نموذج Exllama\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # طلب مسار ملف PDF\n",
        "    pdf_path = input(\"أدخل مسار ملف PDF (مثال: /content/drive/MyDrive/book.pdf): \").strip()\n",
        "    text = extract_text_from_pdf(pdf_path)\n",
        "    if not text:\n",
        "        return\n",
        "\n",
        "    # تقسيم النص وإنشاء قاعدة المعرفة\n",
        "    chunks = split_text(text)\n",
        "\n",
        "    print(\"جاري تحميل نموذج التضمين...\")\n",
        "    embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    kb = create_knowledge_base(chunks, embedding_model)\n",
        "\n",
        "    # طلب مسار نموذج Exllama\n",
        "    model_path = input(\"أدخل مسار نموذج Exllama (مثال: /content/Phi-3.5-mini-instruct-exl2): \").strip()\n",
        "\n",
        "    # حلقة استعلام المستخدم\n",
        "    while True:\n",
        "        query = input(\"\\nأدخل سؤالك (أو اكتب 'خروج' للخروج): \").strip()\n",
        "        if query.lower() in ['خروج', 'exit']:\n",
        "            break\n",
        "\n",
        "        context = search_knowledge_base(kb, query)\n",
        "        prompt = f\"السياق:\\n{context}\\n\\nالسؤال:\\n{query}\\n\\nالإجابة:\"\n",
        "\n",
        "        answer = generate_answer_exllama(model_path, prompt)\n",
        "\n",
        "        print(\"\\nالإجابة:\")\n",
        "        print(\"-\" * 50)\n",
        "        if answer:\n",
        "            print(answer)\n",
        "        else:\n",
        "            print(\"لم يتم توليد إجابة.\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    print(\"تم إنهاء البرنامج.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMEMJYfZzaO0",
        "outputId": "cf75e2e1-bf32-40ff-ac42-4fefb3abbe24"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "برنامج RAG مع كتاب PDF باستخدام نموذج Exllama\n",
            "==================================================\n",
            "أدخل مسار ملف PDF (مثال: /content/drive/MyDrive/book.pdf): /content/g.pdf\n",
            "جاري استخراج النص من الملف: /content/g.pdf\n",
            "تم استخراج 21 حرف من النص.\n",
            "جاري تقسيم النص إلى أجزاء...\n",
            "تم تقسيم النص إلى 1 جزء.\n",
            "جاري تحميل نموذج التضمين...\n",
            "جاري إنشاء قاعدة المعرفة...\n",
            "تم إنشاء قاعدة المعرفة بنجاح.\n",
            "أدخل مسار نموذج Exllama (مثال: /content/Phi-3.5-mini-instruct-exl2): What is my name?\n",
            "\n",
            "أدخل سؤالك (أو اكتب 'خروج' للخروج): خروج\n",
            "تم إنهاء البرنامج.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    print(f\"جاري استخراج النص من الملف: {pdf_path}\")\n",
        "    text = \"\"\n",
        "    try:\n",
        "        pdf_reader = PdfReader(pdf_path)\n",
        "        for page in pdf_reader.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                # تنظيف بسيط للنص؛ يمكنك تعديل ذلك حسب الحاجة\n",
        "                page_text = page_text.replace(\"\\r\", \" \").replace(\"\\t\", \" \")\n",
        "                text += page_text + \"\\n\"\n",
        "        print(f\"تم استخراج {len(text)} حرف من النص.\")\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"حدث خطأ أثناء قراءة ملف PDF: {e}\")\n",
        "        return None\n",
        "\n",
        "def split_text(text):\n",
        "    print(\"جاري تقسيم النص إلى أجزاء...\")\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, length_function=len)\n",
        "    chunks = splitter.split_text(text)\n",
        "    print(f\"تم تقسيم النص إلى {len(chunks)} جزء.\")\n",
        "    return chunks\n",
        "\n",
        "def create_knowledge_base(chunks, embedding_model):\n",
        "    print(\"جاري إنشاء قاعدة المعرفة...\")\n",
        "    kb = FAISS.from_texts(chunks, embedding_model)\n",
        "    print(\"تم إنشاء قاعدة المعرفة بنجاح.\")\n",
        "    return kb\n",
        "\n",
        "def search_knowledge_base(kb, query, k=4):\n",
        "    print(f\"جاري البحث عن: {query}\")\n",
        "    docs = kb.similarity_search(query, k=k)\n",
        "    context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "    return context\n",
        "\n",
        "def generate_answer_exllama(model_path, prompt):\n",
        "    \"\"\"\n",
        "    يقوم هذا الدالة باستدعاء سكريبت exllama_inference.py مع تمرير البرومبت والنموذج.\n",
        "    يتم إضافة معلمات إضافية للتوليد (max_new_tokens, temperature, top_p).\n",
        "    \"\"\"\n",
        "    command = [\n",
        "        \"python\", \"exllama_inference.py\",\n",
        "        \"--model\", model_path,\n",
        "        \"--prompt\", prompt,\n",
        "        \"--max_new_tokens\", \"64\",\n",
        "        \"--temperature\", \"0.7\",\n",
        "        \"--top_p\", \"0.9\"\n",
        "    ]\n",
        "    print(\"Executing command:\", \" \".join(command))\n",
        "    try:\n",
        "        result = subprocess.run(command, capture_output=True, text=True, check=True)\n",
        "        output = result.stdout.strip()\n",
        "        return output\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(\"حدث خطأ أثناء استدعاء Exllama:\", e)\n",
        "        print(\"stderr:\", e.stderr)\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    print(\"برنامج RAG مع كتاب PDF باستخدام نموذج Exllama\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # طلب مسار ملف PDF\n",
        "    pdf_path = input(\"أدخل مسار ملف PDF (مثال: /content/drive/MyDrive/book.pdf): \").strip()\n",
        "    text = extract_text_from_pdf(pdf_path)\n",
        "    if not text:\n",
        "        return\n",
        "\n",
        "    # تقسيم النص وإنشاء قاعدة المعرفة\n",
        "    chunks = split_text(text)\n",
        "\n",
        "    print(\"جاري تحميل نموذج التضمين...\")\n",
        "    embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    kb = create_knowledge_base(chunks, embedding_model)\n",
        "\n",
        "    # طلب مسار نموذج Exllama\n",
        "    model_path = input(\"أدخل مسار نموذج Exllama (مثال: /content/Phi-3.5-mini-instruct-exl2): \").strip()\n",
        "\n",
        "    # حلقة استعلام المستخدم\n",
        "    while True:\n",
        "        query = input(\"\\nأدخل سؤالك (أو اكتب 'خروج' للخروج): \").strip()\n",
        "        if query.lower() in ['خروج', 'exit']:\n",
        "            break\n",
        "\n",
        "        context = search_knowledge_base(kb, query)\n",
        "        prompt = f\"السياق:\\n{context}\\n\\nالسؤال:\\n{query}\\n\\nالإجابة:\"\n",
        "\n",
        "        answer = generate_answer_exllama(model_path, prompt)\n",
        "\n",
        "        print(\"\\nالإجابة:\")\n",
        "        print(\"-\" * 50)\n",
        "        if answer:\n",
        "            print(answer)\n",
        "        else:\n",
        "            print(\"لم يتم توليد إجابة.\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    print(\"تم إنهاء البرنامج.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W216kgq3zafl",
        "outputId": "518ce5ae-245d-4636-d36c-864895ff55f1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "برنامج RAG مع كتاب PDF باستخدام نموذج Exllama\n",
            "==================================================\n",
            "أدخل مسار ملف PDF (مثال: /content/drive/MyDrive/book.pdf): /content/g.pdf\n",
            "جاري استخراج النص من الملف: /content/g.pdf\n",
            "تم استخراج 21 حرف من النص.\n",
            "جاري تقسيم النص إلى أجزاء...\n",
            "تم تقسيم النص إلى 1 جزء.\n",
            "جاري تحميل نموذج التضمين...\n",
            "جاري إنشاء قاعدة المعرفة...\n",
            "تم إنشاء قاعدة المعرفة بنجاح.\n",
            "أدخل مسار نموذج Exllama (مثال: /content/Phi-3.5-mini-instruct-exl2): /content/Phi-3.5-mini-instruct-exl2\n",
            "\n",
            "أدخل سؤالك (أو اكتب 'خروج' للخروج): \"What is my name?\"\n",
            "جاري البحث عن: \"What is my name?\"\n",
            "Executing command: python exllama_inference.py --model /content/Phi-3.5-mini-instruct-exl2 --prompt السياق:\n",
            "my name is very good\n",
            "\n",
            "السؤال:\n",
            "\"What is my name?\"\n",
            "\n",
            "الإجابة: --max_new_tokens 64 --temperature 0.7 --top_p 0.9\n",
            "حدث خطأ أثناء استدعاء Exllama: Command '['python', 'exllama_inference.py', '--model', '/content/Phi-3.5-mini-instruct-exl2', '--prompt', 'السياق:\\nmy name is very good\\n\\nالسؤال:\\n\"What is my name?\"\\n\\nالإجابة:', '--max_new_tokens', '64', '--temperature', '0.7', '--top_p', '0.9']' returned non-zero exit status 2.\n",
            "stderr: python3: can't open file '/content/exllama_inference.py': [Errno 2] No such file or directory\n",
            "\n",
            "\n",
            "الإجابة:\n",
            "--------------------------------------------------\n",
            "لم يتم توليد إجابة.\n",
            "--------------------------------------------------\n",
            "\n",
            "أدخل سؤالك (أو اكتب 'خروج' للخروج): خروج\n",
            "تم إنهاء البرنامج.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "git clone https://github.com/turboderp/exllamav2\n",
        "cd exllamav2\n",
        "pip install -r requirements.txt\n",
        "pip install .\n",
        "\n",
        "python test_inference.py -m <path_to_model> -p \"Once upon a time,\"\n",
        "# Append the '--gpu_split auto' flag for multi-GPU inference"
      ],
      "metadata": {
        "id": "QHpqPNHI062V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/turboderp/exllamav2\n",
        "%cd exllamav2\n",
        "!pip install -r requirements.txt\n",
        "!pip install .\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiUnIyN90-GG",
        "outputId": "6c82351b-60de-4a28-daf5-6964e8d40ba8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'exllamav2'...\n",
            "remote: Enumerating objects: 8145, done.\u001b[K\n",
            "remote: Counting objects: 100% (3373/3373), done.\u001b[K\n",
            "remote: Compressing objects: 100% (971/971), done.\u001b[K\n",
            "remote: Total 8145 (delta 2474), reused 2430 (delta 2402), pack-reused 4772 (from 2)\u001b[K\n",
            "Receiving objects: 100% (8145/8145), 21.93 MiB | 26.61 MiB/s, done.\n",
            "Resolving deltas: 100% (5872/5872), done.\n",
            "/content/exllamav2\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.2.2)\n",
            "Collecting ninja (from -r requirements.txt (line 2))\n",
            "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (0.45.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (75.2.0)\n",
            "Collecting fastparquet (from -r requirements.txt (line 5))\n",
            "  Downloading fastparquet-2024.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: torch>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (2.6.0+cu124)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (0.5.3)\n",
            "Requirement already satisfied: sentencepiece>=0.1.97 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (2.18.0)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (15.0.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (2024.11.6)\n",
            "Collecting numpy~=1.26.4 (from -r requirements.txt (line 12))\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (0.21.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (13.9.4)\n",
            "Requirement already satisfied: pillow>=9.1.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (11.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: cramjam>=2.3 in /usr/local/lib/python3.11/dist-packages (from fastparquet->-r requirements.txt (line 5)) (2.9.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from fastparquet->-r requirements.txt (line 5)) (2025.3.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from fastparquet->-r requirements.txt (line 5)) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->-r requirements.txt (line 6)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->-r requirements.txt (line 6)) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->-r requirements.txt (line 6)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->-r requirements.txt (line 6)) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->-r requirements.txt (line 6)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->-r requirements.txt (line 6)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->-r requirements.txt (line 6)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->-r requirements.txt (line 6)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->-r requirements.txt (line 6)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->-r requirements.txt (line 6)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->-r requirements.txt (line 6)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->-r requirements.txt (line 6)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->-r requirements.txt (line 6)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->-r requirements.txt (line 6)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->-r requirements.txt (line 6)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->-r requirements.txt (line 6)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->-r requirements.txt (line 6)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->-r requirements.txt (line 6)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->-r requirements.txt (line 6)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.2.0->-r requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers->-r requirements.txt (line 13)) (0.30.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->-r requirements.txt (line 14)) (3.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->-r requirements.txt (line 13)) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->-r requirements.txt (line 13)) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->-r requirements.txt (line 13)) (4.67.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->-r requirements.txt (line 14)) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.2.0->-r requirements.txt (line 6)) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers->-r requirements.txt (line 13)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers->-r requirements.txt (line 13)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers->-r requirements.txt (line 13)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers->-r requirements.txt (line 13)) (2025.1.31)\n",
            "Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastparquet-2024.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, ninja, fastparquet\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "Successfully installed fastparquet-2024.11.0 ninja-1.11.1.4 numpy-1.26.4\n",
            "Processing /content/exllamav2\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from exllamav2==0.2.8) (2.2.2)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from exllamav2==0.2.8) (1.11.1.4)\n",
            "Requirement already satisfied: fastparquet in /usr/local/lib/python3.11/dist-packages (from exllamav2==0.2.8) (2024.11.0)\n",
            "Requirement already satisfied: torch>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from exllamav2==0.2.8) (2.6.0+cu124)\n",
            "Requirement already satisfied: safetensors>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from exllamav2==0.2.8) (0.5.3)\n",
            "Requirement already satisfied: sentencepiece>=0.1.97 in /usr/local/lib/python3.11/dist-packages (from exllamav2==0.2.8) (0.2.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from exllamav2==0.2.8) (2.18.0)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.11/dist-packages (from exllamav2==0.2.8) (15.0.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from exllamav2==0.2.8) (2024.11.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from exllamav2==0.2.8) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from exllamav2==0.2.8) (13.9.4)\n",
            "Requirement already satisfied: pillow>=9.1.0 in /usr/local/lib/python3.11/dist-packages (from exllamav2==0.2.8) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->exllamav2==0.2.8) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->exllamav2==0.2.8) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->exllamav2==0.2.8) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->exllamav2==0.2.8) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->exllamav2==0.2.8) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->exllamav2==0.2.8) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->exllamav2==0.2.8) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->exllamav2==0.2.8) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->exllamav2==0.2.8) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->exllamav2==0.2.8) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->exllamav2==0.2.8) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->exllamav2==0.2.8) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->exllamav2==0.2.8) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->exllamav2==0.2.8) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->exllamav2==0.2.8) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->exllamav2==0.2.8) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->exllamav2==0.2.8) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->exllamav2==0.2.8) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->exllamav2==0.2.8) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->exllamav2==0.2.8) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.2.0->exllamav2==0.2.8) (1.3.0)\n",
            "Requirement already satisfied: cramjam>=2.3 in /usr/local/lib/python3.11/dist-packages (from fastparquet->exllamav2==0.2.8) (2.9.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from fastparquet->exllamav2==0.2.8) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->exllamav2==0.2.8) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->exllamav2==0.2.8) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->exllamav2==0.2.8) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->exllamav2==0.2.8) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->exllamav2==0.2.8) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->exllamav2==0.2.8) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.2.0->exllamav2==0.2.8) (3.0.2)\n",
            "Building wheels for collected packages: exllamav2\n",
            "  Building wheel for exllamav2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for exllamav2: filename=exllamav2-0.2.8-cp311-cp311-linux_x86_64.whl size=54493186 sha256=ef5317282f5924de1a28a4bd2d6ffbd7f7afe07319ccbeca3f577a6d9e9173aa\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-akcrcvjv/wheels/b4/4b/d2/15c8ae14306a022cd079278bc37cf80748b39206c089b42f12\n",
            "Successfully built exllamav2\n",
            "Installing collected packages: exllamav2\n",
            "Successfully installed exllamav2-0.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MKX1B8xF0-nG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6aJyKSgt1Phl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LsV7Yrk81Pfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    print(f\"جاري استخراج النص من الملف: {pdf_path}\")\n",
        "    text = \"\"\n",
        "    try:\n",
        "        pdf_reader = PdfReader(pdf_path)\n",
        "        for page in pdf_reader.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                # تنظيف بسيط للنص؛ يمكنك تعديل ذلك حسب الحاجة\n",
        "                page_text = page_text.replace(\"\\r\", \" \").replace(\"\\t\", \" \")\n",
        "                text += page_text + \"\\n\"\n",
        "        print(f\"تم استخراج {len(text)} حرف من النص.\")\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"حدث خطأ أثناء قراءة ملف PDF: {e}\")\n",
        "        return None\n",
        "\n",
        "def split_text(text):\n",
        "    print(\"جاري تقسيم النص إلى أجزاء...\")\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, length_function=len)\n",
        "    chunks = splitter.split_text(text)\n",
        "    print(f\"تم تقسيم النص إلى {len(chunks)} جزء.\")\n",
        "    return chunks\n",
        "\n",
        "def create_knowledge_base(chunks, embedding_model):\n",
        "    print(\"جاري إنشاء قاعدة المعرفة...\")\n",
        "    kb = FAISS.from_texts(chunks, embedding_model)\n",
        "    print(\"تم إنشاء قاعدة المعرفة بنجاح.\")\n",
        "    return kb\n",
        "\n",
        "def search_knowledge_base(kb, query, k=4):\n",
        "    print(f\"جاري البحث عن: {query}\")\n",
        "    docs = kb.similarity_search(query, k=k)\n",
        "    context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "    return context\n",
        "\n",
        "def generate_answer_exllama(model_path, prompt):\n",
        "    \"\"\"\n",
        "    يقوم هذا الدالة باستدعاء سكريبت exllama_inference.py مع تمرير البرومبت والنموذج.\n",
        "    يتم إضافة معلمات إضافية للتوليد (max_new_tokens, temperature, top_p).\n",
        "    \"\"\"\n",
        "    command = [\n",
        "        \"python\", \"exllama_inference.py\",\n",
        "        \"--model\", model_path,\n",
        "        \"--prompt\", prompt,\n",
        "        \"--max_new_tokens\", \"64\",\n",
        "        \"--temperature\", \"0.7\",\n",
        "        \"--top_p\", \"0.9\"\n",
        "    ]\n",
        "    print(\"Executing command:\", \" \".join(command))\n",
        "    try:\n",
        "        result = subprocess.run(command, capture_output=True, text=True, check=True)\n",
        "        output = result.stdout.strip()\n",
        "        return output\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(\"حدث خطأ أثناء استدعاء Exllama:\", e)\n",
        "        print(\"stderr:\", e.stderr)\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    print(\"برنامج RAG مع كتاب PDF باستخدام نموذج Exllama\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # طلب مسار ملف PDF\n",
        "    pdf_path = input(\"أدخل مسار ملف PDF (مثال: /content/drive/MyDrive/book.pdf): \").strip()\n",
        "    text = extract_text_from_pdf(pdf_path)\n",
        "    if not text:\n",
        "        return\n",
        "\n",
        "    # تقسيم النص وإنشاء قاعدة المعرفة\n",
        "    chunks = split_text(text)\n",
        "\n",
        "    print(\"جاري تحميل نموذج التضمين...\")\n",
        "    embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    kb = create_knowledge_base(chunks, embedding_model)\n",
        "\n",
        "    # طلب مسار نموذج Exllama\n",
        "    model_path = input(\"أدخل مسار نموذج Exllama (مثال: /content/Phi-3.5-mini-instruct-exl2): \").strip()\n",
        "\n",
        "    # حلقة استعلام المستخدم\n",
        "    while True:\n",
        "        query = input(\"\\nأدخل سؤالك (أو اكتب 'خروج' للخروج): \").strip()\n",
        "        if query.lower() in ['خروج', 'exit']:\n",
        "            break\n",
        "\n",
        "        context = search_knowledge_base(kb, query)\n",
        "        prompt = f\"السياق:\\n{context}\\n\\nالسؤال:\\n{query}\\n\\nالإجابة:\"\n",
        "\n",
        "        answer = generate_answer_exllama(model_path, prompt)\n",
        "\n",
        "        print(\"\\nالإجابة:\")\n",
        "        print(\"-\" * 50)\n",
        "        if answer:\n",
        "            print(answer)\n",
        "        else:\n",
        "            print(\"لم يتم توليد إجابة.\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    print(\"تم إنهاء البرنامج.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "zkrd4k_81Pbz",
        "outputId": "d6bf733a-1843-490f-b8a4-78a10c3dfd0e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "برنامج RAG مع كتاب PDF باستخدام نموذج Exllama\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-75bcb7a402b0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-75bcb7a402b0>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# طلب مسار ملف PDF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mpdf_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"أدخل مسار ملف PDF (مثال: /content/drive/MyDrive/book.pdf): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_text_from_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "/content/exllamav2/test_inference.py"
      ],
      "metadata": {
        "id": "I9lldlMH14Be"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "شغال"
      ],
      "metadata": {
        "id": "nW1CI1bU5tQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    print(f\"جاري استخراج النص من الملف: {pdf_path}\")\n",
        "    text = \"\"\n",
        "    try:\n",
        "        pdf_reader = PdfReader(pdf_path)\n",
        "        for page in pdf_reader.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                # تنظيف بسيط للنص؛ يمكنك تعديل ذلك حسب الحاجة\n",
        "                page_text = page_text.replace(\"\\r\", \" \").replace(\"\\t\", \" \")\n",
        "                text += page_text + \"\\n\"\n",
        "        print(f\"تم استخراج {len(text)} حرف من النص.\")\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"حدث خطأ أثناء قراءة ملف PDF: {e}\")\n",
        "        return None\n",
        "\n",
        "def split_text(text):\n",
        "    print(\"جاري تقسيم النص إلى أجزاء...\")\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, length_function=len)\n",
        "    chunks = splitter.split_text(text)\n",
        "    print(f\"تم تقسيم النص إلى {len(chunks)} جزء.\")\n",
        "    return chunks\n",
        "\n",
        "def create_knowledge_base(chunks, embedding_model):\n",
        "    print(\"جاري إنشاء قاعدة المعرفة...\")\n",
        "    kb = FAISS.from_texts(chunks, embedding_model)\n",
        "    print(\"تم إنشاء قاعدة المعرفة بنجاح.\")\n",
        "    return kb\n",
        "\n",
        "def search_knowledge_base(kb, query, k=4):\n",
        "    print(f\"جاري البحث عن: {query}\")\n",
        "    docs = kb.similarity_search(query, k=k)\n",
        "    context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "    return context\n",
        "\n",
        "def generate_answer_exllama(model_path, prompt):\n",
        "    \"\"\"\n",
        "    يقوم هذا الدالة باستدعاء سكريبت الاستدلال الموجود في:\n",
        "    /content/exllamav2/test_inference.py\n",
        "    مع تمرير البرومبت والنموذج ومعلمات التوليد.\n",
        "    \"\"\"\n",
        "    command = [\n",
        "        \"python\", \"/content/exllamav2/test_inference.py\",\n",
        "        \"--model\", model_path,\n",
        "        \"--prompt\", prompt,\n",
        "        \"--max_new_tokens\", \"64\",\n",
        "        \"--temperature\", \"0.7\",\n",
        "        \"--top_p\", \"0.9\"\n",
        "    ]\n",
        "    print(\"Executing command:\", \" \".join(command))\n",
        "    try:\n",
        "        result = subprocess.run(command, capture_output=True, text=True, check=True)\n",
        "        output = result.stdout.strip()\n",
        "        return output\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(\"حدث خطأ أثناء استدعاء Exllama:\", e)\n",
        "        print(\"stderr:\", e.stderr)\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    print(\"برنامج RAG مع كتاب PDF باستخدام نموذج Exllama\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # طلب مسار ملف PDF\n",
        "    pdf_path = input(\"أدخل مسار ملف PDF (مثال: /content/drive/MyDrive/book.pdf): \").strip()\n",
        "    text = extract_text_from_pdf(pdf_path)\n",
        "    if not text:\n",
        "        return\n",
        "\n",
        "    # تقسيم النص وإنشاء قاعدة المعرفة\n",
        "    chunks = split_text(text)\n",
        "\n",
        "    print(\"جاري تحميل نموذج التضمين...\")\n",
        "    embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    kb = create_knowledge_base(chunks, embedding_model)\n",
        "\n",
        "    # طلب مسار نموذج Exllama\n",
        "    model_path = input(\"أدخل مسار نموذج Exllama (مثال: /content/Phi-3.5-mini-instruct-exl2): \").strip()\n",
        "\n",
        "    # حلقة استعلام المستخدم\n",
        "    while True:\n",
        "        query = input(\"\\nأدخل سؤالك (أو اكتب 'خروج' للخروج): \").strip()\n",
        "        if query.lower() in ['خروج', 'exit']:\n",
        "            break\n",
        "\n",
        "        context = search_knowledge_base(kb, query)\n",
        "        prompt = f\"السياق:\\n{context}\\n\\nالسؤال:\\n{query}\\n\\nالإجابة:\"\n",
        "\n",
        "        answer = generate_answer_exllama(model_path, prompt)\n",
        "\n",
        "        print(\"\\nالإجابة:\")\n",
        "        print(\"-\" * 50)\n",
        "        if answer:\n",
        "            print(answer)\n",
        "        else:\n",
        "            print(\"لم يتم توليد إجابة.\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    print(\"تم إنهاء البرنامج.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCS-LJv-12K-",
        "outputId": "a7d9e6b2-5020-4868-cb41-5c5715e17201"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "برنامج RAG مع كتاب PDF باستخدام نموذج Exllama\n",
            "==================================================\n",
            "أدخل مسار ملف PDF (مثال: /content/drive/MyDrive/book.pdf): /content/g.pdf\n",
            "جاري استخراج النص من الملف: /content/g.pdf\n",
            "تم استخراج 21 حرف من النص.\n",
            "جاري تقسيم النص إلى أجزاء...\n",
            "تم تقسيم النص إلى 1 جزء.\n",
            "جاري تحميل نموذج التضمين...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-2e6a132644de>:82: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "جاري إنشاء قاعدة المعرفة...\n",
            "تم إنشاء قاعدة المعرفة بنجاح.\n",
            "أدخل مسار نموذج Exllama (مثال: /content/Phi-3.5-mini-instruct-exl2): /content/Phi-3.5-mini-instruct-exl2\n",
            "\n",
            "أدخل سؤالك (أو اكتب 'خروج' للخروج): \"What is my name?\"\n",
            "جاري البحث عن: \"What is my name?\"\n",
            "Executing command: python /content/exllamav2/test_inference.py --model /content/Phi-3.5-mini-instruct-exl2 --prompt السياق:\n",
            "my name is very good\n",
            "\n",
            "السؤال:\n",
            "\"What is my name?\"\n",
            "\n",
            "الإجابة: --max_new_tokens 64 --temperature 0.7 --top_p 0.9\n",
            "حدث خطأ أثناء استدعاء Exllama: Command '['python', '/content/exllamav2/test_inference.py', '--model', '/content/Phi-3.5-mini-instruct-exl2', '--prompt', 'السياق:\\nmy name is very good\\n\\nالسؤال:\\n\"What is my name?\"\\n\\nالإجابة:', '--max_new_tokens', '64', '--temperature', '0.7', '--top_p', '0.9']' returned non-zero exit status 2.\n",
            "stderr: usage: test_inference.py [-h] [-ed EVAL_DATASET] [-er EVAL_ROWS] [-el EVAL_LENGTH] [-et] [-e8]\n",
            "                         [-eq4] [-eq6] [-eq8] [-ecl] [-p PROMPT] [-pnb] [-t TOKENS] [-ps] [-s]\n",
            "                         [-mix MIX_LAYERS] [-nwu] [-sl] [-sp {wiki2}] [-rr RANK_REDUCE]\n",
            "                         [-mol MAX_OUTPUT_LEN] [-m MODEL_DIR] [-gs GPU_SPLIT] [-tp] [-l LENGTH]\n",
            "                         [-rs ROPE_SCALE] [-ra ROPE_ALPHA] [-ry ROPE_YARN] [-nfa] [-nxf] [-nsdpa]\n",
            "                         [-ng] [-lm] [-ept EXPERTS_PER_TOKEN] [-lq4] [-fst] [-ic]\n",
            "                         [-chunk CHUNK_SIZE]\n",
            "test_inference.py: error: unrecognized arguments: --max_new_tokens 64 --temperature 0.7 --top_p 0.9\n",
            "\n",
            "\n",
            "الإجابة:\n",
            "--------------------------------------------------\n",
            "لم يتم توليد إجابة.\n",
            "--------------------------------------------------\n",
            "\n",
            "أدخل سؤالك (أو اكتب 'خروج' للخروج): خروج\n",
            "تم إنهاء البرنامج.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    print(f\"جاري استخراج النص من الملف: {pdf_path}\")\n",
        "    text = \"\"\n",
        "    try:\n",
        "        pdf_reader = PdfReader(pdf_path)\n",
        "        for page in pdf_reader.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                # تنظيف بسيط للنص؛ يمكنك تعديل ذلك حسب الحاجة\n",
        "                page_text = page_text.replace(\"\\r\", \" \").replace(\"\\t\", \" \")\n",
        "                text += page_text + \"\\n\"\n",
        "        print(f\"تم استخراج {len(text)} حرف من النص.\")\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"حدث خطأ أثناء قراءة ملف PDF: {e}\")\n",
        "        return None\n",
        "\n",
        "def split_text(text):\n",
        "    print(\"جاري تقسيم النص إلى أجزاء...\")\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, length_function=len)\n",
        "    chunks = splitter.split_text(text)\n",
        "    print(f\"تم تقسيم النص إلى {len(chunks)} جزء.\")\n",
        "    return chunks\n",
        "\n",
        "def create_knowledge_base(chunks, embedding_model):\n",
        "    print(\"جاري إنشاء قاعدة المعرفة...\")\n",
        "    kb = FAISS.from_texts(chunks, embedding_model)\n",
        "    print(\"تم إنشاء قاعدة المعرفة بنجاح.\")\n",
        "    return kb\n",
        "\n",
        "def search_knowledge_base(kb, query, k=4):\n",
        "    print(f\"جاري البحث عن: {query}\")\n",
        "    docs = kb.similarity_search(query, k=k)\n",
        "    context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "    return context\n",
        "\n",
        "def generate_answer_exllama(model_path, prompt):\n",
        "    \"\"\"\n",
        "    يقوم هذا الدالة باستدعاء سكريبت الاستدلال الموجود في:\n",
        "    /content/exllamav2/test_inference.py\n",
        "    مع تمرير البرومبت والنموذج ومعلمات التوليد.\n",
        "    \"\"\"\n",
        "    command = [\n",
        "        \"python\", \"/content/exllamav2/test_inference.py\",\n",
        "        \"--model\", model_path,\n",
        "        \"--prompt\", prompt,\n",
        "        \"--max_new_tokens\", \"64\",\n",
        "        \"--temperature\", \"0.7\",\n",
        "        \"--top_p\", \"0.9\"\n",
        "    ]\n",
        "    print(\"Executing command:\", \" \".join(command))\n",
        "    try:\n",
        "        result = subprocess.run(command, capture_output=True, text=True, check=True)\n",
        "        output = result.stdout.strip()\n",
        "        return output\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(\"حدث خطأ أثناء استدعاء Exllama:\", e)\n",
        "        print(\"stderr:\", e.stderr)\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    print(\"برنامج RAG مع كتاب PDF باستخدام نموذج Exllama\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # طلب مسار ملف PDF\n",
        "    pdf_path = input(\"أدخل مسار ملف PDF (مثال: /content/drive/MyDrive/book.pdf): \").strip()\n",
        "    text = extract_text_from_pdf(pdf_path)\n",
        "    if not text:\n",
        "        return\n",
        "\n",
        "    # تقسيم النص وإنشاء قاعدة المعرفة\n",
        "    chunks = split_text(text)\n",
        "\n",
        "    print(\"جاري تحميل نموذج التضمين...\")\n",
        "    embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    kb = create_knowledge_base(chunks, embedding_model)\n",
        "\n",
        "    # طلب مسار نموذج Exllama\n",
        "    model_path = input(\"أدخل مسار نموذج Exllama (مثال: /content/Phi-3.5-mini-instruct-exl2): \").strip()\n",
        "\n",
        "    # حلقة استعلام المستخدم\n",
        "    while True:\n",
        "        query = input(\"\\nأدخل سؤالك (أو اكتب 'خروج' للخروج): \").strip()\n",
        "        if query.lower() in ['خروج', 'exit']:\n",
        "            break\n",
        "\n",
        "        context = search_knowledge_base(kb, query)\n",
        "        prompt = f\"السياق:\\n{context}\\n\\nالسؤال:\\n{query}\\n\\nالإجابة:\"\n",
        "\n",
        "        answer = generate_answer_exllama(model_path, prompt)\n",
        "\n",
        "        print(\"\\nالإجابة:\")\n",
        "        print(\"-\" * 50)\n",
        "        if answer:\n",
        "            print(answer)\n",
        "        else:\n",
        "            print(\"لم يتم توليد إجابة.\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    print(\"تم إنهاء البرنامج.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZinw-RO57Kf",
        "outputId": "cd466887-47e0-4a4d-fa06-2af11386cfc3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "برنامج RAG مع كتاب PDF باستخدام نموذج Exllama\n",
            "==================================================\n",
            "أدخل مسار ملف PDF (مثال: /content/drive/MyDrive/book.pdf): /content/g.pdf\n",
            "جاري استخراج النص من الملف: /content/g.pdf\n",
            "تم استخراج 21 حرف من النص.\n",
            "جاري تقسيم النص إلى أجزاء...\n",
            "تم تقسيم النص إلى 1 جزء.\n",
            "جاري تحميل نموذج التضمين...\n",
            "جاري إنشاء قاعدة المعرفة...\n",
            "تم إنشاء قاعدة المعرفة بنجاح.\n",
            "أدخل مسار نموذج Exllama (مثال: /content/Phi-3.5-mini-instruct-exl2): /content/Phi-3.5-mini-instruct-exl2\n",
            "\n",
            "أدخل سؤالك (أو اكتب 'خروج' للخروج): What is my name?\n",
            "جاري البحث عن: What is my name?\n",
            "Executing command: python /content/exllamav2/test_inference.py --model /content/Phi-3.5-mini-instruct-exl2 --prompt السياق:\n",
            "my name is very good\n",
            "\n",
            "السؤال:\n",
            "What is my name?\n",
            "\n",
            "الإجابة: --max_new_tokens 64 --temperature 0.7 --top_p 0.9\n",
            "حدث خطأ أثناء استدعاء Exllama: Command '['python', '/content/exllamav2/test_inference.py', '--model', '/content/Phi-3.5-mini-instruct-exl2', '--prompt', 'السياق:\\nmy name is very good\\n\\nالسؤال:\\nWhat is my name?\\n\\nالإجابة:', '--max_new_tokens', '64', '--temperature', '0.7', '--top_p', '0.9']' returned non-zero exit status 2.\n",
            "stderr: usage: test_inference.py [-h] [-ed EVAL_DATASET] [-er EVAL_ROWS] [-el EVAL_LENGTH] [-et] [-e8]\n",
            "                         [-eq4] [-eq6] [-eq8] [-ecl] [-p PROMPT] [-pnb] [-t TOKENS] [-ps] [-s]\n",
            "                         [-mix MIX_LAYERS] [-nwu] [-sl] [-sp {wiki2}] [-rr RANK_REDUCE]\n",
            "                         [-mol MAX_OUTPUT_LEN] [-m MODEL_DIR] [-gs GPU_SPLIT] [-tp] [-l LENGTH]\n",
            "                         [-rs ROPE_SCALE] [-ra ROPE_ALPHA] [-ry ROPE_YARN] [-nfa] [-nxf] [-nsdpa]\n",
            "                         [-ng] [-lm] [-ept EXPERTS_PER_TOKEN] [-lq4] [-fst] [-ic]\n",
            "                         [-chunk CHUNK_SIZE]\n",
            "test_inference.py: error: unrecognized arguments: --max_new_tokens 64 --temperature 0.7 --top_p 0.9\n",
            "\n",
            "\n",
            "الإجابة:\n",
            "--------------------------------------------------\n",
            "لم يتم توليد إجابة.\n",
            "--------------------------------------------------\n",
            "\n",
            "أدخل سؤالك (أو اكتب 'خروج' للخروج): خروج\n",
            "تم إنهاء البرنامج.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    print(f\"جاري استخراج النص من الملف: {pdf_path}\")\n",
        "    text = \"\"\n",
        "    try:\n",
        "        pdf_reader = PdfReader(pdf_path)\n",
        "        for page in pdf_reader.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                # تنظيف بسيط للنص؛ يمكنك تعديل ذلك حسب الحاجة\n",
        "                page_text = page_text.replace(\"\\r\", \" \").replace(\"\\t\", \" \")\n",
        "                text += page_text + \"\\n\"\n",
        "        print(f\"تم استخراج {len(text)} حرف من النص.\")\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"حدث خطأ أثناء قراءة ملف PDF: {e}\")\n",
        "        return None\n",
        "\n",
        "def split_text(text):\n",
        "    print(\"جاري تقسيم النص إلى أجزاء...\")\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, length_function=len)\n",
        "    chunks = splitter.split_text(text)\n",
        "    print(f\"تم تقسيم النص إلى {len(chunks)} جزء.\")\n",
        "    return chunks\n",
        "\n",
        "def create_knowledge_base(chunks, embedding_model):\n",
        "    print(\"جاري إنشاء قاعدة المعرفة...\")\n",
        "    kb = FAISS.from_texts(chunks, embedding_model)\n",
        "    print(\"تم إنشاء قاعدة المعرفة بنجاح.\")\n",
        "    return kb\n",
        "\n",
        "def search_knowledge_base(kb, query, k=4):\n",
        "    print(f\"جاري البحث عن: {query}\")\n",
        "    docs = kb.similarity_search(query, k=k)\n",
        "    context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "    return context\n",
        "\n",
        "def generate_answer_exllama(model_path, prompt):\n",
        "    \"\"\"\n",
        "    يقوم هذا الدالة باستدعاء سكريبت test_inference.py الموجود في:\n",
        "    /content/exllamav2/test_inference.py\n",
        "    مع تمرير نص الاستعلام والنموذج ومعامل الحد الأقصى لطول الناتج.\n",
        "    \"\"\"\n",
        "    command = [\n",
        "        \"python\", \"/content/exllamav2/test_inference.py\",\n",
        "        \"-m\", model_path,\n",
        "        \"-p\", prompt,\n",
        "        \"-mol\", \"64\"\n",
        "    ]\n",
        "    print(\"Executing command:\", \" \".join(command))\n",
        "    try:\n",
        "        result = subprocess.run(command, capture_output=True, text=True, check=True)\n",
        "        output = result.stdout.strip()\n",
        "        return output\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(\"حدث خطأ أثناء استدعاء Exllama:\", e)\n",
        "        print(\"stderr:\", e.stderr)\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    print(\"برنامج RAG مع كتاب PDF باستخدام نموذج Exllama\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # طلب مسار ملف PDF\n",
        "    pdf_path = input(\"أدخل مسار ملف PDF (مثال: /content/drive/MyDrive/book.pdf): \").strip()\n",
        "    text = extract_text_from_pdf(pdf_path)\n",
        "    if not text:\n",
        "        return\n",
        "\n",
        "    # تقسيم النص وإنشاء قاعدة المعرفة\n",
        "    chunks = split_text(text)\n",
        "\n",
        "    print(\"جاري تحميل نموذج التضمين...\")\n",
        "    embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    kb = create_knowledge_base(chunks, embedding_model)\n",
        "\n",
        "    # طلب مسار نموذج Exllama\n",
        "    model_path = input(\"أدخل مسار نموذج Exllama (مثال: /content/Phi-3.5-mini-instruct-exl2): \").strip()\n",
        "\n",
        "    # حلقة استعلام المستخدم\n",
        "    while True:\n",
        "        query = input(\"\\nأدخل سؤالك (أو اكتب 'خروج' للخروج): \").strip()\n",
        "        if query.lower() in ['خروج', 'exit']:\n",
        "            break\n",
        "\n",
        "        context = search_knowledge_base(kb, query)\n",
        "        prompt = f\"السياق:\\n{context}\\n\\nالسؤال:\\n{query}\\n\\nالإجابة:\"\n",
        "\n",
        "        answer = generate_answer_exllama(model_path, prompt)\n",
        "\n",
        "        print(\"\\nالإجابة:\")\n",
        "        print(\"-\" * 50)\n",
        "        if answer:\n",
        "            print(answer)\n",
        "        else:\n",
        "            print(\"لم يتم توليد إجابة.\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    print(\"تم إنهاء البرنامج.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxpXdGjG6UPf",
        "outputId": "ab6667af-7404-4a8f-80db-10d49649433c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "برنامج RAG مع كتاب PDF باستخدام نموذج Exllama\n",
            "==================================================\n",
            "أدخل مسار ملف PDF (مثال: /content/drive/MyDrive/book.pdf): /content/g.pdf\n",
            "جاري استخراج النص من الملف: /content/g.pdf\n",
            "تم استخراج 21 حرف من النص.\n",
            "جاري تقسيم النص إلى أجزاء...\n",
            "تم تقسيم النص إلى 1 جزء.\n",
            "جاري تحميل نموذج التضمين...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-e585a4836fd7>:80: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "جاري إنشاء قاعدة المعرفة...\n",
            "تم إنشاء قاعدة المعرفة بنجاح.\n",
            "أدخل مسار نموذج Exllama (مثال: /content/Phi-3.5-mini-instruct-exl2): /content/Phi-3.5-mini-instruct-exl2\n",
            "\n",
            "أدخل سؤالك (أو اكتب 'خروج' للخروج): what is my name?\n",
            "جاري البحث عن: what is my name?\n",
            "Executing command: python /content/exllamav2/test_inference.py -m /content/Phi-3.5-mini-instruct-exl2 -p السياق:\n",
            "my name is very good\n",
            "\n",
            "السؤال:\n",
            "what is my name?\n",
            "\n",
            "الإجابة: -mol 64\n",
            "حدث خطأ أثناء استدعاء Exllama: Command '['python', '/content/exllamav2/test_inference.py', '-m', '/content/Phi-3.5-mini-instruct-exl2', '-p', 'السياق:\\nmy name is very good\\n\\nالسؤال:\\nwhat is my name?\\n\\nالإجابة:', '-mol', '64']' returned non-zero exit status 1.\n",
            "stderr: Traceback (most recent call last):\n",
            "  File \"/content/exllamav2/test_inference.py\", line 192, in <module>\n",
            "    cache = ExLlamaV2Cache(model) if not model.tp_context else ExLlamaV2Cache_TP(model)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/exllamav2/exllamav2/cache.py\", line 256, in __init__\n",
            "    self.create_state_tensors(copy_from, lazy)\n",
            "  File \"/content/exllamav2/exllamav2/cache.py\", line 91, in create_state_tensors\n",
            "    p_key_states = torch.zeros(self.shape_wk, dtype = self.dtype, device = device).contiguous()\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 486.12 MiB is free. Process 185919 has 232.00 MiB memory in use. Process 188899 has 14.04 GiB memory in use. Of the allocated memory 13.80 GiB is allocated by PyTorch, and 109.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "\n",
            "\n",
            "الإجابة:\n",
            "--------------------------------------------------\n",
            "لم يتم توليد إجابة.\n",
            "--------------------------------------------------\n",
            "\n",
            "أدخل سؤالك (أو اكتب 'خروج' للخروج): خروج\n",
            "تم إنهاء البرنامج.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n"
      ],
      "metadata": {
        "id": "m-Zdtad26UpP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "# تعيين متغير البيئة لتفادي تجزئة الذاكرة\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    print(f\"جاري استخراج النص من الملف: {pdf_path}\")\n",
        "    text = \"\"\n",
        "    try:\n",
        "        pdf_reader = PdfReader(pdf_path)\n",
        "        for page in pdf_reader.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                # تنظيف بسيط للنص؛ يمكنك تعديل ذلك حسب الحاجة\n",
        "                page_text = page_text.replace(\"\\r\", \" \").replace(\"\\t\", \" \")\n",
        "                text += page_text + \"\\n\"\n",
        "        print(f\"تم استخراج {len(text)} حرف من النص.\")\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"حدث خطأ أثناء قراءة ملف PDF: {e}\")\n",
        "        return None\n",
        "\n",
        "def split_text(text):\n",
        "    print(\"جاري تقسيم النص إلى أجزاء...\")\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, length_function=len)\n",
        "    chunks = splitter.split_text(text)\n",
        "    print(f\"تم تقسيم النص إلى {len(chunks)} جزء.\")\n",
        "    return chunks\n",
        "\n",
        "def create_knowledge_base(chunks, embedding_model):\n",
        "    print(\"جاري إنشاء قاعدة المعرفة...\")\n",
        "    kb = FAISS.from_texts(chunks, embedding_model)\n",
        "    print(\"تم إنشاء قاعدة المعرفة بنجاح.\")\n",
        "    return kb\n",
        "\n",
        "def search_knowledge_base(kb, query, k=4):\n",
        "    print(f\"جاري البحث عن: {query}\")\n",
        "    docs = kb.similarity_search(query, k=k)\n",
        "    context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "    return context\n",
        "\n",
        "def generate_answer_exllama(model_path, prompt):\n",
        "    \"\"\"\n",
        "    يقوم هذا الدالة باستدعاء سكريبت test_inference.py الموجود في:\n",
        "    /content/exllamav2/test_inference.py\n",
        "    مع تمرير نص الاستعلام والنموذج ومعامل الحد الأقصى لطول الناتج.\n",
        "    \"\"\"\n",
        "    command = [\n",
        "        \"python\", \"/content/exllamav2/test_inference.py\",\n",
        "        \"-m\", model_path,\n",
        "        \"-p\", prompt,\n",
        "        \"-l\", \"32\",\n",
        "        \"-mol\", \"32\"\n",
        "    ]\n",
        "    print(\"Executing command:\", \" \".join(command))\n",
        "    try:\n",
        "        result = subprocess.run(command, capture_output=True, text=True, check=True)\n",
        "        output = result.stdout.strip()\n",
        "        return output\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(\"حدث خطأ أثناء استدعاء Exllama:\", e)\n",
        "        print(\"stderr:\", e.stderr)\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    print(\"برنامج RAG مع كتاب PDF باستخدام نموذج Exllama\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # طلب مسار ملف PDF\n",
        "    pdf_path = input(\"أدخل مسار ملف PDF (مثال: /content/drive/MyDrive/book.pdf): \").strip()\n",
        "    text = extract_text_from_pdf(pdf_path)\n",
        "    if not text:\n",
        "        return\n",
        "\n",
        "    # تقسيم النص وإنشاء قاعدة المعرفة\n",
        "    chunks = split_text(text)\n",
        "\n",
        "    print(\"جاري تحميل نموذج التضمين...\")\n",
        "    embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    kb = create_knowledge_base(chunks, embedding_model)\n",
        "\n",
        "    # طلب مسار نموذج Exllama\n",
        "    model_path = input(\"أدخل مسار نموذج Exllama (مثال: /content/Phi-3.5-mini-instruct-exl2): \").strip()\n",
        "\n",
        "    # حلقة استعلام المستخدم\n",
        "    while True:\n",
        "        query = input(\"\\nأدخل سؤالك (أو اكتب 'خروج' للخروج): \").strip()\n",
        "        if query.lower() in ['خروج', 'exit']:\n",
        "            break\n",
        "\n",
        "        context = search_knowledge_base(kb, query)\n",
        "        prompt = f\"السياق:\\n{context}\\n\\nالسؤال:\\n{query}\\n\\nالإجابة:\"\n",
        "\n",
        "        answer = generate_answer_exllama(model_path, prompt)\n",
        "\n",
        "        print(\"\\nالإجابة:\")\n",
        "        print(\"-\" * 50)\n",
        "        if answer:\n",
        "            print(answer)\n",
        "        else:\n",
        "            print(\"لم يتم توليد إجابة.\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    print(\"تم إنهاء البرنامج.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQgxE7kH7SDQ",
        "outputId": "80a8c1e6-2e12-4d92-daa1-7f9a0084f457"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "برنامج RAG مع كتاب PDF باستخدام نموذج Exllama\n",
            "==================================================\n",
            "أدخل مسار ملف PDF (مثال: /content/drive/MyDrive/book.pdf): /content/g.pdf\n",
            "جاري استخراج النص من الملف: /content/g.pdf\n",
            "تم استخراج 21 حرف من النص.\n",
            "جاري تقسيم النص إلى أجزاء...\n",
            "تم تقسيم النص إلى 1 جزء.\n",
            "جاري تحميل نموذج التضمين...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-e72c2285d504>:84: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "جاري إنشاء قاعدة المعرفة...\n",
            "تم إنشاء قاعدة المعرفة بنجاح.\n",
            "أدخل مسار نموذج Exllama (مثال: /content/Phi-3.5-mini-instruct-exl2): /content/Phi-3.5-mini-instruct-exl2\n",
            "\n",
            "أدخل سؤالك (أو اكتب 'خروج' للخروج): what is my name?\n",
            "جاري البحث عن: what is my name?\n",
            "Executing command: python /content/exllamav2/test_inference.py -m /content/Phi-3.5-mini-instruct-exl2 -p السياق:\n",
            "my name is very good\n",
            "\n",
            "السؤال:\n",
            "what is my name?\n",
            "\n",
            "الإجابة: -l 32 -mol 32\n",
            "حدث خطأ أثناء استدعاء Exllama: Command '['python', '/content/exllamav2/test_inference.py', '-m', '/content/Phi-3.5-mini-instruct-exl2', '-p', 'السياق:\\nmy name is very good\\n\\nالسؤال:\\nwhat is my name?\\n\\nالإجابة:', '-l', '32', '-mol', '32']' returned non-zero exit status 1.\n",
            "stderr: Traceback (most recent call last):\n",
            "  File \"/content/exllamav2/test_inference.py\", line 214, in <module>\n",
            "    output = generator.generate_simple(args.prompt, settings, args.tokens, token_healing = True, add_bos = not args.prompt_no_bos)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/exllamav2/exllamav2/generator/base.py\", line 265, in generate_simple\n",
            "    indexed_embeddings = input_embeddings).float().cpu()\n",
            "                                           ^^^^^\n",
            "AttributeError: 'NoneType' object has no attribute 'float'\n",
            "\n",
            "\n",
            "الإجابة:\n",
            "--------------------------------------------------\n",
            "لم يتم توليد إجابة.\n",
            "--------------------------------------------------\n",
            "\n",
            "أدخل سؤالك (أو اكتب 'خروج' للخروج): خروج\n",
            "تم إنهاء البرنامج.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "command = [\n",
        "    \"python\", \"/content/exllamav2/test_inference.py\",\n",
        "    \"-m\", model_path,\n",
        "    \"-p\", prompt,\n",
        "    \"-l\", \"128\",\n",
        "    \"-mol\", \"32\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "mjonpaL884IK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python /content/exllamav2/test_inference.py -http\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMFzmUQ67e0w",
        "outputId": "6e6ae004-f29c-462e-90ec-802914e63d2f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: test_inference.py [-h] [-ed EVAL_DATASET] [-er EVAL_ROWS] [-el EVAL_LENGTH] [-et] [-e8]\n",
            "                         [-eq4] [-eq6] [-eq8] [-ecl] [-p PROMPT] [-pnb] [-t TOKENS] [-ps] [-s]\n",
            "                         [-mix MIX_LAYERS] [-nwu] [-sl] [-sp {wiki2}] [-rr RANK_REDUCE]\n",
            "                         [-mol MAX_OUTPUT_LEN] [-m MODEL_DIR] [-gs GPU_SPLIT] [-tp] [-l LENGTH]\n",
            "                         [-rs ROPE_SCALE] [-ra ROPE_ALPHA] [-ry ROPE_YARN] [-nfa] [-nxf] [-nsdpa]\n",
            "                         [-ng] [-lm] [-ept EXPERTS_PER_TOKEN] [-lq4] [-fst] [-ic]\n",
            "                         [-chunk CHUNK_SIZE]\n",
            "\n",
            "Test inference on ExLlamaV2 model\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  -ed EVAL_DATASET, --eval_dataset EVAL_DATASET\n",
            "                        Perplexity evaluation dataset (.parquet file)\n",
            "  -er EVAL_ROWS, --eval_rows EVAL_ROWS\n",
            "                        Number of rows to apply from dataset (default 128)\n",
            "  -el EVAL_LENGTH, --eval_length EVAL_LENGTH\n",
            "                        Max no. tokens per sample\n",
            "  -et, --eval_token     Evaluate perplexity on token-by-token inference using cache\n",
            "  -e8, --eval_token_8bit\n",
            "                        Evaluate perplexity on token-by-token inference using 8-bit (FP8) cache\n",
            "  -eq4, --eval_token_q4\n",
            "                        Evaluate perplexity on token-by-token inference using Q4 cache\n",
            "  -eq6, --eval_token_q6\n",
            "                        Evaluate perplexity on token-by-token inference using Q6 cache\n",
            "  -eq8, --eval_token_q8\n",
            "                        Evaluate perplexity on token-by-token inference using Q8 cache\n",
            "  -ecl, --eval_context_lens\n",
            "                        Evaluate perplexity at range of context lengths\n",
            "  -p PROMPT, --prompt PROMPT\n",
            "                        Generate from prompt (basic sampling settings)\n",
            "  -pnb, --prompt_no_bos\n",
            "                        Don't add BOS token to prompt\n",
            "  -t TOKENS, --tokens TOKENS\n",
            "                        Max no. tokens\n",
            "  -ps, --prompt_speed   Test prompt processing (batch) speed over context length\n",
            "  -s, --speed           Test raw generation speed over context length\n",
            "  -mix MIX_LAYERS, --mix_layers MIX_LAYERS\n",
            "                        Load replacement layers from secondary model. Example: --mix_layers\n",
            "                        1,6-7:/mnt/models/other_model\n",
            "  -nwu, --no_warmup     Skip warmup before testing model\n",
            "  -sl, --stream_layers  Load model layer by layer (perplexity evaluation only)\n",
            "  -sp {wiki2}, --standard_perplexity {wiki2}\n",
            "                        Run standard (HF) perplexity test, stride 512 (experimental)\n",
            "  -rr RANK_REDUCE, --rank_reduce RANK_REDUCE\n",
            "                        Rank-reduction for MLP layers of model, in reverse order (for\n",
            "                        experimentation)\n",
            "  -mol MAX_OUTPUT_LEN, --max_output_len MAX_OUTPUT_LEN\n",
            "                        Set max output chunk size (incompatible with ppl tests)\n",
            "  -m MODEL_DIR, --model_dir MODEL_DIR\n",
            "                        Path to model directory\n",
            "  -gs GPU_SPLIT, --gpu_split GPU_SPLIT\n",
            "                        \"auto\", or VRAM allocation per GPU in GB. \"auto\" is implied by default in\n",
            "                        tensor-parallel mode.\n",
            "  -tp, --tensor_parallel\n",
            "                        Load in tensor-parallel mode (not fully supported for all models)\n",
            "  -l LENGTH, --length LENGTH\n",
            "                        Maximum sequence length\n",
            "  -rs ROPE_SCALE, --rope_scale ROPE_SCALE\n",
            "                        RoPE scaling factor\n",
            "  -ra ROPE_ALPHA, --rope_alpha ROPE_ALPHA\n",
            "                        RoPE alpha value (NTK)\n",
            "  -ry ROPE_YARN, --rope_yarn ROPE_YARN\n",
            "                        Set RoPE YaRN factor (use default max_seq_len as\n",
            "                        original_max_position_embeddings if not configured)\n",
            "  -nfa, --no_flash_attn\n",
            "                        Disable Flash Attention\n",
            "  -nxf, --no_xformers   Disable xformers, an alternative plan of flash attn for older devices\n",
            "  -nsdpa, --no_sdpa     Disable Torch SDPA\n",
            "  -ng, --no_graphs      Disable Graphs\n",
            "  -lm, --low_mem        Enable VRAM optimizations, potentially trading off speed\n",
            "  -ept EXPERTS_PER_TOKEN, --experts_per_token EXPERTS_PER_TOKEN\n",
            "                        Override MoE model's default number of experts per token\n",
            "  -lq4, --load_q4       Load weights in Q4 mode\n",
            "  -fst, --fast_safetensors\n",
            "                        Deprecated (does nothing)\n",
            "  -ic, --ignore_compatibility\n",
            "                        Do not override model config options in case of compatibility issues\n",
            "  -chunk CHUNK_SIZE, --chunk_size CHUNK_SIZE\n",
            "                        Chunk size ('input length')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python /content/exllamav2/test_inference.py -http\n",
        "\n",
        "\n",
        "usage: test_inference.py [-h] [-ed EVAL_DATASET] [-er EVAL_ROWS] [-el EVAL_LENGTH] [-et] [-e8]\n",
        "                         [-eq4] [-eq6] [-eq8] [-ecl] [-p PROMPT] [-pnb] [-t TOKENS] [-ps] [-s]\n",
        "                         [-mix MIX_LAYERS] [-nwu] [-sl] [-sp {wiki2}] [-rr RANK_REDUCE]\n",
        "                         [-mol MAX_OUTPUT_LEN] [-m MODEL_DIR] [-gs GPU_SPLIT] [-tp] [-l LENGTH]\n",
        "                         [-rs ROPE_SCALE] [-ra ROPE_ALPHA] [-ry ROPE_YARN] [-nfa] [-nxf] [-nsdpa]\n",
        "                         [-ng] [-lm] [-ept EXPERTS_PER_TOKEN] [-lq4] [-fst] [-ic]\n",
        "                         [-chunk CHUNK_SIZE]\n",
        "\n",
        "Test inference on ExLlamaV2 model\n",
        "\n",
        "options:\n",
        "  -h, --help            show this help message and exit\n",
        "  -ed EVAL_DATASET, --eval_dataset EVAL_DATASET\n",
        "                        Perplexity evaluation dataset (.parquet file)\n",
        "  -er EVAL_ROWS, --eval_rows EVAL_ROWS\n",
        "                        Number of rows to apply from dataset (default 128)\n",
        "  -el EVAL_LENGTH, --eval_length EVAL_LENGTH\n",
        "                        Max no. tokens per sample\n",
        "  -et, --eval_token     Evaluate perplexity on token-by-token inference using cache\n",
        "  -e8, --eval_token_8bit\n",
        "                        Evaluate perplexity on token-by-token inference using 8-bit (FP8) cache\n",
        "  -eq4, --eval_token_q4\n",
        "                        Evaluate perplexity on token-by-token inference using Q4 cache\n",
        "  -eq6, --eval_token_q6\n",
        "                        Evaluate perplexity on token-by-token inference using Q6 cache\n",
        "  -eq8, --eval_token_q8\n",
        "                        Evaluate perplexity on token-by-token inference using Q8 cache\n",
        "  -ecl, --eval_context_lens\n",
        "                        Evaluate perplexity at range of context lengths\n",
        "  -p PROMPT, --prompt PROMPT\n",
        "                        Generate from prompt (basic sampling settings)\n",
        "  -pnb, --prompt_no_bos\n",
        "                        Don't add BOS token to prompt\n",
        "  -t TOKENS, --tokens TOKENS\n",
        "                        Max no. tokens\n",
        "  -ps, --prompt_speed   Test prompt processing (batch) speed over context length\n",
        "  -s, --speed           Test raw generation speed over context length\n",
        "  -mix MIX_LAYERS, --mix_layers MIX_LAYERS\n",
        "                        Load replacement layers from secondary model. Example: --mix_layers\n",
        "                        1,6-7:/mnt/models/other_model\n",
        "  -nwu, --no_warmup     Skip warmup before testing model\n",
        "  -sl, --stream_layers  Load model layer by layer (perplexity evaluation only)\n",
        "  -sp {wiki2}, --standard_perplexity {wiki2}\n",
        "                        Run standard (HF) perplexity test, stride 512 (experimental)\n",
        "  -rr RANK_REDUCE, --rank_reduce RANK_REDUCE\n",
        "                        Rank-reduction for MLP layers of model, in reverse order (for\n",
        "                        experimentation)\n",
        "  -mol MAX_OUTPUT_LEN, --max_output_len MAX_OUTPUT_LEN\n",
        "                        Set max output chunk size (incompatible with ppl tests)\n",
        "  -m MODEL_DIR, --model_dir MODEL_DIR\n",
        "                        Path to model directory\n",
        "  -gs GPU_SPLIT, --gpu_split GPU_SPLIT\n",
        "                        \"auto\", or VRAM allocation per GPU in GB. \"auto\" is implied by default in\n",
        "                        tensor-parallel mode.\n",
        "  -tp, --tensor_parallel\n",
        "                        Load in tensor-parallel mode (not fully supported for all models)\n",
        "  -l LENGTH, --length LENGTH\n",
        "                        Maximum sequence length\n",
        "  -rs ROPE_SCALE, --rope_scale ROPE_SCALE\n",
        "                        RoPE scaling factor\n",
        "  -ra ROPE_ALPHA, --rope_alpha ROPE_ALPHA\n",
        "                        RoPE alpha value (NTK)\n",
        "  -ry ROPE_YARN, --rope_yarn ROPE_YARN\n",
        "                        Set RoPE YaRN factor (use default max_seq_len as\n",
        "                        original_max_position_embeddings if not configured)\n",
        "  -nfa, --no_flash_attn\n",
        "                        Disable Flash Attention\n",
        "  -nxf, --no_xformers   Disable xformers, an alternative plan of flash attn for older devices\n",
        "  -nsdpa, --no_sdpa     Disable Torch SDPA\n",
        "  -ng, --no_graphs      Disable Graphs\n",
        "  -lm, --low_mem        Enable VRAM optimizations, potentially trading off speed\n",
        "  -ept EXPERTS_PER_TOKEN, --experts_per_token EXPERTS_PER_TOKEN\n",
        "                        Override MoE model's default number of experts per token\n",
        "  -lq4, --load_q4       Load weights in Q4 mode\n",
        "  -fst, --fast_safetensors\n",
        "                        Deprecated (does nothing)\n",
        "  -ic, --ignore_compatibility\n",
        "                        Do not override model config options in case of compatibility issues\n",
        "  -chunk CHUNK_SIZE, --chunk_size CHUNK_SIZE\n",
        "                        Chunk size ('input length')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_kl8ucNI7niI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}